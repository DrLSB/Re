2023-05-31 16:18:19.466 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=324]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=24]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=6912]
7260 parameters will be pruned
-------------

2023-05-31 16:18:19.467 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=4500]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=14400]
18950 parameters will be pruned
-------------

2023-05-31 16:18:19.468 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=28800]
37625 parameters will be pruned
-------------

2023-05-31 16:18:19.469 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=17901]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=3264]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=3264]
24531 parameters will be pruned
-------------

2023-05-31 16:18:19.470 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(77, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=1925]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[206, 207, 208, 209, 210, 211, 216, 217, 221, 225, 226, 229, 230, 234, 237, 238, 240, 241, 242, 243, 245, 246, 249, 251, 253], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[206, 207, 208, 209, 210, 211, 216, 217, 221, 225, 226, 229, 230, 234, 237, 238, 240, 241, 242, 243, 245, 246, 249, 251, 253], NumPruned=6400]
8375 parameters will be pruned
-------------

2023-05-31 16:18:19.471 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(77, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=1925]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=14400]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 231])>, Index=[134, 135, 136, 137, 138, 141, 147, 148, 150, 151, 155, 157, 158, 162, 164, 165, 169, 170, 176, 179, 180, 183, 185, 188, 189], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(231, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[134, 135, 136, 137, 138, 141, 147, 148, 150, 151, 155, 157, 158, 162, 164, 165, 169, 170, 176, 179, 180, 183, 185, 188, 189], NumPruned=6400]
22775 parameters will be pruned
-------------

2023-05-31 16:18:19.472 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=14400]
23225 parameters will be pruned
-------------

2023-05-31 16:18:19.473 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=14400]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 167, 206])>, Index=[69, 71, 73, 74, 76, 80, 81, 83, 85, 87, 90, 92, 97, 98, 100, 105, 108, 109, 110, 111, 112, 115, 116, 121, 124], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(206, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[69, 71, 73, 74, 76, 80, 81, 83, 85, 87, 90, 92, 97, 98, 100, 105, 108, 109, 110, 111, 112, 115, 116, 121, 124], NumPruned=6400]
29625 parameters will be pruned
-------------

2023-05-31 16:18:19.474 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=14400]
23225 parameters will be pruned
-------------

2023-05-31 16:18:19.475 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 103, 142, 181])>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(181, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=6400]
15225 parameters will be pruned
-------------

2023-05-31 16:18:19.477 | INFO     | __main__:layer_pruning:76 -   Params: 37196556 => 36985740

2023-05-31 16:18:19.515 | ERROR    | __main__:<module>:94 - An error has been caught in function '<module>', process 'MainProcess' (12472), thread 'MainThread' (2392):
Traceback (most recent call last):

> File "E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\tools\prunmodel.py", line 94, in <module>
    layer_pruning(r'E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\runs\train\v7_results\exp_yuan_B8_Epoch200\weights\best.pt')
    └ <function layer_pruning at 0x00000000116268B0>

  File "E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\tools\prunmodel.py", line 88, in layer_pruning
    torch.save(model_, '../model_data/layer_pruning.pt')
    │     │    └ {'epoch': -1, 'best_fitness': array([     0.3795]), 'model': Model(
    │     │        (model): Sequential(
    │     │          (0): Conv(
    │     │            (conv): Conv2...
    │     └ <function save at 0x00000000059104C0>
    └ <module 'torch' from 'D:\\annconda\\lib\\site-packages\\torch\\__init__.py'>

  File "D:\annconda\lib\site-packages\torch\serialization.py", line 377, in save
    with _open_file_like(f, 'wb') as opened_file:
         │               └ '../model_data/layer_pruning.pt'
         └ <function _open_file_like at 0x000000000590EA60>

  File "D:\annconda\lib\site-packages\torch\serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
           │          │               └ 'wb'
           │          └ '../model_data/layer_pruning.pt'
           └ <class 'torch.serialization._open_file'>

  File "D:\annconda\lib\site-packages\torch\serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
          │           │                   │     └ 'wb'
          │           │                   └ '../model_data/layer_pruning.pt'
          │           └ <torch.serialization._open_file object at 0x0000000013A96D60>
          └ <class 'torch.serialization._open_file'>

FileNotFoundError: [Errno 2] No such file or directory: '../model_data/layer_pruning.pt'
2023-05-31 16:18:56.531 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=324]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=24]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=6912]
7260 parameters will be pruned
-------------

2023-05-31 16:18:56.532 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=4500]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=14400]
18950 parameters will be pruned
-------------

2023-05-31 16:18:56.533 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=28800]
37625 parameters will be pruned
-------------

2023-05-31 16:18:56.534 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=17901]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=3264]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=3264]
24531 parameters will be pruned
-------------

2023-05-31 16:18:56.535 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(77, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=1925]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[206, 207, 208, 209, 210, 211, 216, 217, 221, 225, 226, 229, 230, 234, 237, 238, 240, 241, 242, 243, 245, 246, 249, 251, 253], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[206, 207, 208, 209, 210, 211, 216, 217, 221, 225, 226, 229, 230, 234, 237, 238, 240, 241, 242, 243, 245, 246, 249, 251, 253], NumPruned=6400]
8375 parameters will be pruned
-------------

2023-05-31 16:18:56.536 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(77, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=1925]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=14400]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 231])>, Index=[134, 135, 136, 137, 138, 141, 147, 148, 150, 151, 155, 157, 158, 162, 164, 165, 169, 170, 176, 179, 180, 183, 185, 188, 189], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(231, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[134, 135, 136, 137, 138, 141, 147, 148, 150, 151, 155, 157, 158, 162, 164, 165, 169, 170, 176, 179, 180, 183, 185, 188, 189], NumPruned=6400]
22775 parameters will be pruned
-------------

2023-05-31 16:18:56.537 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=14400]
23225 parameters will be pruned
-------------

2023-05-31 16:18:56.540 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=14400]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 167, 206])>, Index=[69, 71, 73, 74, 76, 80, 81, 83, 85, 87, 90, 92, 97, 98, 100, 105, 108, 109, 110, 111, 112, 115, 116, 121, 124], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(206, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[69, 71, 73, 74, 76, 80, 81, 83, 85, 87, 90, 92, 97, 98, 100, 105, 108, 109, 110, 111, 112, 115, 116, 121, 124], NumPruned=6400]
29625 parameters will be pruned
-------------

2023-05-31 16:18:56.541 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=14400]
23225 parameters will be pruned
-------------

2023-05-31 16:18:56.542 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 103, 142, 181])>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(181, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=6400]
15225 parameters will be pruned
-------------

2023-05-31 16:18:56.543 | INFO     | __main__:layer_pruning:76 -   Params: 37196556 => 36985740

2023-05-31 16:18:56.682 | INFO     | __main__:layer_pruning:90 - 剪枝完成

2023-05-31 16:19:53.078 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=324]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=24]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[4, 11, 12, 14, 18, 19, 20, 22, 23, 24, 28, 31], NumPruned=6912]
7260 parameters will be pruned
-------------

2023-05-31 16:19:53.079 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(20, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=4500]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 7, 8, 16, 19, 20, 24, 26, 27, 30, 33, 37, 39, 42, 44, 49, 54, 56, 57, 58, 59, 62, 63], NumPruned=14400]
18950 parameters will be pruned
-------------

2023-05-31 16:19:53.080 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 21, 24, 26, 27, 31, 36, 39, 45, 49, 53, 54, 55, 56, 59, 60], NumPruned=28800]
37625 parameters will be pruned
-------------

2023-05-31 16:19:53.081 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(39, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=17901]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=3264]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 9, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 29, 34, 38, 40, 41, 43, 44, 47, 48, 49, 53, 57, 58, 60, 61, 66, 69, 70, 74, 75, 76, 79, 80, 86, 96, 99, 100, 101, 102, 104, 105, 110, 112, 114, 115, 121], NumPruned=3264]
24531 parameters will be pruned
-------------

2023-05-31 16:19:53.087 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(77, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=1925]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[14, 15, 16, 17, 18, 19, 24, 25, 29, 33, 34, 37, 38, 42, 45, 46, 48, 49, 50, 51, 53, 54, 57, 59, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[206, 207, 208, 209, 210, 211, 216, 217, 221, 225, 226, 229, 230, 234, 237, 238, 240, 241, 242, 243, 245, 246, 249, 251, 253], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[206, 207, 208, 209, 210, 211, 216, 217, 221, 225, 226, 229, 230, 234, 237, 238, 240, 241, 242, 243, 245, 246, 249, 251, 253], NumPruned=6400]
8375 parameters will be pruned
-------------

2023-05-31 16:19:53.088 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(77, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=1925]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[6, 7, 8, 9, 10, 13, 19, 20, 22, 23, 27, 29, 30, 34, 36, 37, 41, 42, 48, 51, 52, 55, 57, 60, 61], NumPruned=14400]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 231])>, Index=[134, 135, 136, 137, 138, 141, 147, 148, 150, 151, 155, 157, 158, 162, 164, 165, 169, 170, 176, 179, 180, 183, 185, 188, 189], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(231, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[134, 135, 136, 137, 138, 141, 147, 148, 150, 151, 155, 157, 158, 162, 164, 165, 169, 170, 176, 179, 180, 183, 185, 188, 189], NumPruned=6400]
22775 parameters will be pruned
-------------

2023-05-31 16:19:53.089 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 5, 7, 15, 16, 17, 22, 24, 26, 28, 30, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 61, 62, 63], NumPruned=14400]
23225 parameters will be pruned
-------------

2023-05-31 16:19:53.089 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[5, 7, 9, 10, 12, 16, 17, 19, 21, 23, 26, 28, 33, 34, 36, 41, 44, 45, 46, 47, 48, 51, 52, 57, 60], NumPruned=14400]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 167, 206])>, Index=[69, 71, 73, 74, 76, 80, 81, 83, 85, 87, 90, 92, 97, 98, 100, 105, 108, 109, 110, 111, 112, 115, 116, 121, 124], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(206, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[69, 71, 73, 74, 76, 80, 81, 83, 85, 87, 90, 92, 97, 98, 100, 105, 108, 109, 110, 111, 112, 115, 116, 121, 124], NumPruned=6400]
29625 parameters will be pruned
-------------

2023-05-31 16:19:53.091 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 9, 11, 12, 13, 17, 18, 19, 20, 21, 27, 28, 31, 33, 34, 36, 37, 38, 39, 45, 48, 52, 53, 58], NumPruned=14400]
23225 parameters will be pruned
-------------

2023-05-31 16:19:53.092 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=8775]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 103, 142, 181])>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(181, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 6, 10, 13, 17, 19, 20, 22, 23, 24, 27, 32, 34, 39, 42, 44, 47, 49, 52, 53, 55, 58], NumPruned=6400]
15225 parameters will be pruned
-------------

2023-05-31 16:19:53.093 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.11.conv (Conv2d(156, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 7, 8, 10, 13, 19, 22, 25, 26, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 49, 50, 52, 53, 56, 59, 60, 64, 65, 67, 74, 75, 78, 83, 84, 85, 88, 91, 92, 94, 97, 99, 100, 105, 106, 108, 111, 112, 117, 118, 123, 125, 126, 127, 129, 140, 142, 143, 145, 146, 147, 149, 150, 151, 154, 157, 160, 161, 162, 164, 171, 176, 177, 181, 182, 192, 193, 195, 196, 198, 199, 200, 203, 206, 216, 219, 222, 226, 228, 231, 232, 235, 238, 241, 243, 248, 251, 252, 253, 255], NumPruned=15912]
[ <DEP: prune_conv => prune_batchnorm on model.11.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 5, 7, 8, 10, 13, 19, 22, 25, 26, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 49, 50, 52, 53, 56, 59, 60, 64, 65, 67, 74, 75, 78, 83, 84, 85, 88, 91, 92, 94, 97, 99, 100, 105, 106, 108, 111, 112, 117, 118, 123, 125, 126, 127, 129, 140, 142, 143, 145, 146, 147, 149, 150, 151, 154, 157, 160, 161, 162, 164, 171, 176, 177, 181, 182, 192, 193, 195, 196, 198, 199, 200, 203, 206, 216, 219, 222, 226, 228, 231, 232, 235, 238, 241, 243, 248, 251, 252, 253, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 7, 8, 10, 13, 19, 22, 25, 26, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 49, 50, 52, 53, 56, 59, 60, 64, 65, 67, 74, 75, 78, 83, 84, 85, 88, 91, 92, 94, 97, 99, 100, 105, 106, 108, 111, 112, 117, 118, 123, 125, 126, 127, 129, 140, 142, 143, 145, 146, 147, 149, 150, 151, 154, 157, 160, 161, 162, 164, 171, 176, 177, 181, 182, 192, 193, 195, 196, 198, 199, 200, 203, 206, 216, 219, 222, 226, 228, 231, 232, 235, 238, 241, 243, 248, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.14.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 7, 8, 10, 13, 19, 22, 25, 26, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 49, 50, 52, 53, 56, 59, 60, 64, 65, 67, 74, 75, 78, 83, 84, 85, 88, 91, 92, 94, 97, 99, 100, 105, 106, 108, 111, 112, 117, 118, 123, 125, 126, 127, 129, 140, 142, 143, 145, 146, 147, 149, 150, 151, 154, 157, 160, 161, 162, 164, 171, 176, 177, 181, 182, 192, 193, 195, 196, 198, 199, 200, 203, 206, 216, 219, 222, 226, 228, 231, 232, 235, 238, 241, 243, 248, 251, 252, 253, 255], NumPruned=13056]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 5, 7, 8, 10, 13, 19, 22, 25, 26, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 49, 50, 52, 53, 56, 59, 60, 64, 65, 67, 74, 75, 78, 83, 84, 85, 88, 91, 92, 94, 97, 99, 100, 105, 106, 108, 111, 112, 117, 118, 123, 125, 126, 127, 129, 140, 142, 143, 145, 146, 147, 149, 150, 151, 154, 157, 160, 161, 162, 164, 171, 176, 177, 181, 182, 192, 193, 195, 196, 198, 199, 200, 203, 206, 216, 219, 222, 226, 228, 231, 232, 235, 238, 241, 243, 248, 251, 252, 253, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.13.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 4, 5, 7, 8, 10, 13, 19, 22, 25, 26, 31, 33, 34, 35, 36, 37, 39, 41, 42, 44, 49, 50, 52, 53, 56, 59, 60, 64, 65, 67, 74, 75, 78, 83, 84, 85, 88, 91, 92, 94, 97, 99, 100, 105, 106, 108, 111, 112, 117, 118, 123, 125, 126, 127, 129, 140, 142, 143, 145, 146, 147, 149, 150, 151, 154, 157, 160, 161, 162, 164, 171, 176, 177, 181, 182, 192, 193, 195, 196, 198, 199, 200, 203, 206, 216, 219, 222, 226, 228, 231, 232, 235, 238, 241, 243, 248, 251, 252, 253, 255], NumPruned=13056]
42228 parameters will be pruned
-------------

2023-05-31 16:19:53.098 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.13.conv (Conv2d(154, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[4, 10, 13, 14, 16, 17, 18, 21, 26, 27, 29, 30, 36, 37, 38, 40, 41, 43, 44, 46, 53, 55, 57, 59, 64, 66, 69, 72, 73, 76, 78, 80, 81, 82, 86, 88, 91, 97, 99, 100, 101, 105, 106, 108, 109, 113, 116, 120, 121, 124, 127], NumPruned=7854]
[ <DEP: prune_conv => prune_batchnorm on model.13.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 10, 13, 14, 16, 17, 18, 21, 26, 27, 29, 30, 36, 37, 38, 40, 41, 43, 44, 46, 53, 55, 57, 59, 64, 66, 69, 72, 73, 76, 78, 80, 81, 82, 86, 88, 91, 97, 99, 100, 101, 105, 106, 108, 109, 113, 116, 120, 121, 124, 127], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 10, 13, 14, 16, 17, 18, 21, 26, 27, 29, 30, 36, 37, 38, 40, 41, 43, 44, 46, 53, 55, 57, 59, 64, 66, 69, 72, 73, 76, 78, 80, 81, 82, 86, 88, 91, 97, 99, 100, 101, 105, 106, 108, 109, 113, 116, 120, 121, 124, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256])>, Index=[132, 138, 141, 142, 144, 145, 146, 149, 154, 155, 157, 158, 164, 165, 166, 168, 169, 171, 172, 174, 181, 183, 185, 187, 192, 194, 197, 200, 201, 204, 206, 208, 209, 210, 214, 216, 219, 225, 227, 228, 229, 233, 234, 236, 237, 241, 244, 248, 249, 252, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[132, 138, 141, 142, 144, 145, 146, 149, 154, 155, 157, 158, 164, 165, 166, 168, 169, 171, 172, 174, 181, 183, 185, 187, 192, 194, 197, 200, 201, 204, 206, 208, 209, 210, 214, 216, 219, 225, 227, 228, 229, 233, 234, 236, 237, 241, 244, 248, 249, 252, 255], NumPruned=6528]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[132, 138, 141, 142, 144, 145, 146, 149, 154, 155, 157, 158, 164, 165, 166, 168, 169, 171, 172, 174, 181, 183, 185, 187, 192, 194, 197, 200, 201, 204, 206, 208, 209, 210, 214, 216, 219, 225, 227, 228, 229, 233, 234, 236, 237, 241, 244, 248, 249, 252, 255], NumPruned=6528]
21012 parameters will be pruned
-------------

2023-05-31 16:19:53.099 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.14.conv (Conv2d(154, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 4, 6, 9, 11, 18, 20, 22, 23, 26, 28, 29, 33, 36, 38, 39, 40, 42, 45, 47, 50, 52, 54, 56, 58, 62, 63, 68, 70, 71, 78, 80, 87, 88, 90, 93, 94, 95, 96, 98, 99, 102, 107, 108, 109, 110, 113, 114, 117, 118, 120], NumPruned=7854]
[ <DEP: prune_conv => prune_batchnorm on model.14.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 6, 9, 11, 18, 20, 22, 23, 26, 28, 29, 33, 36, 38, 39, 40, 42, 45, 47, 50, 52, 54, 56, 58, 62, 63, 68, 70, 71, 78, 80, 87, 88, 90, 93, 94, 95, 96, 98, 99, 102, 107, 108, 109, 110, 113, 114, 117, 118, 120], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 6, 9, 11, 18, 20, 22, 23, 26, 28, 29, 33, 36, 38, 39, 40, 42, 45, 47, 50, 52, 54, 56, 58, 62, 63, 68, 70, 71, 78, 80, 87, 88, 90, 93, 94, 95, 96, 98, 99, 102, 107, 108, 109, 110, 113, 114, 117, 118, 120], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.15.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[2, 4, 6, 9, 11, 18, 20, 22, 23, 26, 28, 29, 33, 36, 38, 39, 40, 42, 45, 47, 50, 52, 54, 56, 58, 62, 63, 68, 70, 71, 78, 80, 87, 88, 90, 93, 94, 95, 96, 98, 99, 102, 107, 108, 109, 110, 113, 114, 117, 118, 120], NumPruned=58752]
66708 parameters will be pruned
-------------

2023-05-31 16:19:53.100 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.15.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 3, 6, 7, 12, 14, 20, 21, 31, 32, 34, 38, 41, 43, 45, 47, 51, 52, 53, 59, 65, 69, 71, 72, 73, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 93, 95, 98, 100, 102, 105, 106, 108, 112, 113, 116, 117, 120, 122, 123, 126], NumPruned=35343]
[ <DEP: prune_conv => prune_batchnorm on model.15.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 6, 7, 12, 14, 20, 21, 31, 32, 34, 38, 41, 43, 45, 47, 51, 52, 53, 59, 65, 69, 71, 72, 73, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 93, 95, 98, 100, 102, 105, 106, 108, 112, 113, 116, 117, 120, 122, 123, 126], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 6, 7, 12, 14, 20, 21, 31, 32, 34, 38, 41, 43, 45, 47, 51, 52, 53, 59, 65, 69, 71, 72, 73, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 93, 95, 98, 100, 102, 105, 106, 108, 112, 113, 116, 117, 120, 122, 123, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 205])>, Index=[1, 3, 6, 7, 12, 14, 20, 21, 31, 32, 34, 38, 41, 43, 45, 47, 51, 52, 53, 59, 65, 69, 71, 72, 73, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 93, 95, 98, 100, 102, 105, 106, 108, 112, 113, 116, 117, 120, 122, 123, 126], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.18.conv (Conv2d(205, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 6, 7, 12, 14, 20, 21, 31, 32, 34, 38, 41, 43, 45, 47, 51, 52, 53, 59, 65, 69, 71, 72, 73, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 93, 95, 98, 100, 102, 105, 106, 108, 112, 113, 116, 117, 120, 122, 123, 126], NumPruned=6528]
[ <DEP: _prune_concat => prune_related_conv on model.17.conv (Conv2d(205, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 6, 7, 12, 14, 20, 21, 31, 32, 34, 38, 41, 43, 45, 47, 51, 52, 53, 59, 65, 69, 71, 72, 73, 75, 77, 78, 79, 80, 84, 85, 87, 88, 90, 93, 95, 98, 100, 102, 105, 106, 108, 112, 113, 116, 117, 120, 122, 123, 126], NumPruned=6528]
48501 parameters will be pruned
-------------

2023-05-31 16:19:53.102 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.17.conv (Conv2d(154, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 6, 7, 9, 10, 11, 17, 21, 25, 27, 30, 33, 34, 39, 43, 44, 49, 50, 51, 52, 61, 62, 66, 67, 68, 71, 76, 77, 78, 82, 84, 90, 91, 95, 96, 97, 98, 101, 105, 109, 112, 115, 116, 117, 120, 121, 122, 123], NumPruned=7854]
[ <DEP: prune_conv => prune_batchnorm on model.17.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 6, 7, 9, 10, 11, 17, 21, 25, 27, 30, 33, 34, 39, 43, 44, 49, 50, 51, 52, 61, 62, 66, 67, 68, 71, 76, 77, 78, 82, 84, 90, 91, 95, 96, 97, 98, 101, 105, 109, 112, 115, 116, 117, 120, 121, 122, 123], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 6, 7, 9, 10, 11, 17, 21, 25, 27, 30, 33, 34, 39, 43, 44, 49, 50, 51, 52, 61, 62, 66, 67, 68, 71, 76, 77, 78, 82, 84, 90, 91, 95, 96, 97, 98, 101, 105, 109, 112, 115, 116, 117, 120, 121, 122, 123], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 512])>, Index=[384, 387, 388, 389, 390, 391, 393, 394, 395, 401, 405, 409, 411, 414, 417, 418, 423, 427, 428, 433, 434, 435, 436, 445, 446, 450, 451, 452, 455, 460, 461, 462, 466, 468, 474, 475, 479, 480, 481, 482, 485, 489, 493, 496, 499, 500, 501, 504, 505, 506, 507], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[384, 387, 388, 389, 390, 391, 393, 394, 395, 401, 405, 409, 411, 414, 417, 418, 423, 427, 428, 433, 434, 435, 436, 445, 446, 450, 451, 452, 455, 460, 461, 462, 466, 468, 474, 475, 479, 480, 481, 482, 485, 489, 493, 496, 499, 500, 501, 504, 505, 506, 507], NumPruned=26112]
34068 parameters will be pruned
-------------

2023-05-31 16:19:53.103 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.18.conv (Conv2d(154, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 4, 6, 8, 10, 18, 19, 24, 25, 26, 28, 30, 31, 33, 34, 35, 39, 41, 42, 48, 49, 54, 55, 60, 61, 62, 65, 66, 69, 70, 75, 78, 79, 82, 87, 89, 91, 92, 93, 99, 101, 104, 109, 113, 116, 117, 119, 123, 124, 127], NumPruned=7854]
[ <DEP: prune_conv => prune_batchnorm on model.18.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 6, 8, 10, 18, 19, 24, 25, 26, 28, 30, 31, 33, 34, 35, 39, 41, 42, 48, 49, 54, 55, 60, 61, 62, 65, 66, 69, 70, 75, 78, 79, 82, 87, 89, 91, 92, 93, 99, 101, 104, 109, 113, 116, 117, 119, 123, 124, 127], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 6, 8, 10, 18, 19, 24, 25, 26, 28, 30, 31, 33, 34, 35, 39, 41, 42, 48, 49, 54, 55, 60, 61, 62, 65, 66, 69, 70, 75, 78, 79, 82, 87, 89, 91, 92, 93, 99, 101, 104, 109, 113, 116, 117, 119, 123, 124, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.19.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 6, 8, 10, 18, 19, 24, 25, 26, 28, 30, 31, 33, 34, 35, 39, 41, 42, 48, 49, 54, 55, 60, 61, 62, 65, 66, 69, 70, 75, 78, 79, 82, 87, 89, 91, 92, 93, 99, 101, 104, 109, 113, 116, 117, 119, 123, 124, 127], NumPruned=58752]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 384, 461])>, Index=[257, 258, 260, 262, 264, 266, 274, 275, 280, 281, 282, 284, 286, 287, 289, 290, 291, 295, 297, 298, 304, 305, 310, 311, 316, 317, 318, 321, 322, 325, 326, 331, 334, 335, 338, 343, 345, 347, 348, 349, 355, 357, 360, 365, 369, 372, 373, 375, 379, 380, 383], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(461, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 260, 262, 264, 266, 274, 275, 280, 281, 282, 284, 286, 287, 289, 290, 291, 295, 297, 298, 304, 305, 310, 311, 316, 317, 318, 321, 322, 325, 326, 331, 334, 335, 338, 343, 345, 347, 348, 349, 355, 357, 360, 365, 369, 372, 373, 375, 379, 380, 383], NumPruned=26112]
92820 parameters will be pruned
-------------

2023-05-31 16:19:53.105 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.19.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 11, 12, 14, 15, 19, 22, 23, 25, 26, 28, 29, 30, 35, 38, 41, 42, 44, 45, 46, 48, 52, 53, 56, 57, 58, 60, 64, 67, 73, 77, 80, 81, 89, 90, 91, 93, 95, 99, 101, 102, 106, 107, 112, 116, 117, 118, 121, 125], NumPruned=35343]
[ <DEP: prune_conv => prune_batchnorm on model.19.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 11, 12, 14, 15, 19, 22, 23, 25, 26, 28, 29, 30, 35, 38, 41, 42, 44, 45, 46, 48, 52, 53, 56, 57, 58, 60, 64, 67, 73, 77, 80, 81, 89, 90, 91, 93, 95, 99, 101, 102, 106, 107, 112, 116, 117, 118, 121, 125], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 11, 12, 14, 15, 19, 22, 23, 25, 26, 28, 29, 30, 35, 38, 41, 42, 44, 45, 46, 48, 52, 53, 56, 57, 58, 60, 64, 67, 73, 77, 80, 81, 89, 90, 91, 93, 95, 99, 101, 102, 106, 107, 112, 116, 117, 118, 121, 125], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.20.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 11, 12, 14, 15, 19, 22, 23, 25, 26, 28, 29, 30, 35, 38, 41, 42, 44, 45, 46, 48, 52, 53, 56, 57, 58, 60, 64, 67, 73, 77, 80, 81, 89, 90, 91, 93, 95, 99, 101, 102, 106, 107, 112, 116, 117, 118, 121, 125], NumPruned=58752]
94197 parameters will be pruned
-------------

2023-05-31 16:19:53.106 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.20.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 13, 17, 29, 33, 36, 39, 40, 42, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 58, 61, 62, 64, 66, 69, 70, 71, 72, 76, 78, 83, 86, 88, 91, 94, 96, 97, 98, 102, 104, 107, 108, 109, 110, 117, 120, 125, 127], NumPruned=35343]
[ <DEP: prune_conv => prune_batchnorm on model.20.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 6, 13, 17, 29, 33, 36, 39, 40, 42, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 58, 61, 62, 64, 66, 69, 70, 71, 72, 76, 78, 83, 86, 88, 91, 94, 96, 97, 98, 102, 104, 107, 108, 109, 110, 117, 120, 125, 127], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 6, 13, 17, 29, 33, 36, 39, 40, 42, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 58, 61, 62, 64, 66, 69, 70, 71, 72, 76, 78, 83, 86, 88, 91, 94, 96, 97, 98, 102, 104, 107, 108, 109, 110, 117, 120, 125, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.21.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 13, 17, 29, 33, 36, 39, 40, 42, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 58, 61, 62, 64, 66, 69, 70, 71, 72, 76, 78, 83, 86, 88, 91, 94, 96, 97, 98, 102, 104, 107, 108, 109, 110, 117, 120, 125, 127], NumPruned=58752]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 256, 333, 410])>, Index=[128, 130, 132, 134, 141, 145, 157, 161, 164, 167, 168, 170, 172, 174, 175, 176, 177, 178, 180, 181, 183, 184, 186, 189, 190, 192, 194, 197, 198, 199, 200, 204, 206, 211, 214, 216, 219, 222, 224, 225, 226, 230, 232, 235, 236, 237, 238, 245, 248, 253, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(410, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 132, 134, 141, 145, 157, 161, 164, 167, 168, 170, 172, 174, 175, 176, 177, 178, 180, 181, 183, 184, 186, 189, 190, 192, 194, 197, 198, 199, 200, 204, 206, 211, 214, 216, 219, 222, 224, 225, 226, 230, 232, 235, 236, 237, 238, 245, 248, 253, 255], NumPruned=26112]
120309 parameters will be pruned
-------------

2023-05-31 16:19:53.108 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.21.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 9, 10, 11, 13, 19, 25, 28, 29, 33, 34, 36, 40, 44, 46, 48, 52, 53, 54, 61, 62, 63, 64, 67, 68, 78, 81, 82, 84, 86, 87, 88, 91, 95, 97, 100, 102, 103, 106, 112, 113, 116, 118, 119, 122, 123, 125], NumPruned=35343]
[ <DEP: prune_conv => prune_batchnorm on model.21.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 9, 10, 11, 13, 19, 25, 28, 29, 33, 34, 36, 40, 44, 46, 48, 52, 53, 54, 61, 62, 63, 64, 67, 68, 78, 81, 82, 84, 86, 87, 88, 91, 95, 97, 100, 102, 103, 106, 112, 113, 116, 118, 119, 122, 123, 125], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 9, 10, 11, 13, 19, 25, 28, 29, 33, 34, 36, 40, 44, 46, 48, 52, 53, 54, 61, 62, 63, 64, 67, 68, 78, 81, 82, 84, 86, 87, 88, 91, 95, 97, 100, 102, 103, 106, 112, 113, 116, 118, 119, 122, 123, 125], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.22.conv (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 9, 10, 11, 13, 19, 25, 28, 29, 33, 34, 36, 40, 44, 46, 48, 52, 53, 54, 61, 62, 63, 64, 67, 68, 78, 81, 82, 84, 86, 87, 88, 91, 95, 97, 100, 102, 103, 106, 112, 113, 116, 118, 119, 122, 123, 125], NumPruned=58752]
94197 parameters will be pruned
-------------

2023-05-31 16:19:53.109 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.22.conv (Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 4, 11, 16, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 38, 40, 41, 43, 44, 47, 52, 58, 59, 61, 64, 67, 71, 73, 74, 75, 80, 82, 86, 88, 89, 91, 96, 97, 100, 103, 104, 105, 106, 109, 116, 117, 119, 122, 123, 124, 126], NumPruned=35343]
[ <DEP: prune_conv => prune_batchnorm on model.22.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 11, 16, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 38, 40, 41, 43, 44, 47, 52, 58, 59, 61, 64, 67, 71, 73, 74, 75, 80, 82, 86, 88, 89, 91, 96, 97, 100, 103, 104, 105, 106, 109, 116, 117, 119, 122, 123, 124, 126], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 11, 16, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 38, 40, 41, 43, 44, 47, 52, 58, 59, 61, 64, 67, 71, 73, 74, 75, 80, 82, 86, 88, 89, 91, 96, 97, 100, 103, 104, 105, 106, 109, 116, 117, 119, 122, 123, 124, 126], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 128, 205, 282, 359])>, Index=[1, 4, 11, 16, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 38, 40, 41, 43, 44, 47, 52, 58, 59, 61, 64, 67, 71, 73, 74, 75, 80, 82, 86, 88, 89, 91, 96, 97, 100, 103, 104, 105, 106, 109, 116, 117, 119, 122, 123, 124, 126], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.24.conv (Conv2d(359, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 11, 16, 18, 20, 21, 23, 24, 25, 29, 30, 31, 32, 38, 40, 41, 43, 44, 47, 52, 58, 59, 61, 64, 67, 71, 73, 74, 75, 80, 82, 86, 88, 89, 91, 96, 97, 100, 103, 104, 105, 106, 109, 116, 117, 119, 122, 123, 124, 126], NumPruned=26112]
61557 parameters will be pruned
-------------

2023-05-31 16:19:53.110 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.24.conv (Conv2d(308, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=62832]
[ <DEP: prune_conv => prune_batchnorm on model.24.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=408]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.66.conv (Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=26112]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.27.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=52224]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.26.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 6, 7, 11, 13, 17, 18, 23, 32, 39, 40, 41, 44, 46, 53, 59, 60, 62, 66, 68, 69, 70, 73, 74, 75, 77, 79, 81, 87, 90, 92, 95, 96, 97, 104, 105, 107, 108, 109, 114, 117, 118, 121, 128, 132, 136, 139, 141, 142, 145, 146, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 163, 165, 171, 174, 177, 178, 181, 182, 183, 184, 186, 189, 190, 191, 192, 196, 202, 205, 209, 210, 213, 214, 216, 218, 219, 221, 223, 225, 229, 231, 234, 236, 241, 244, 246, 249, 250, 251, 252, 253, 254, 256, 257, 262, 265, 268, 269, 271, 272, 273, 276, 277, 279, 280, 281, 288, 293, 296, 299, 305, 308, 309, 313, 314, 315, 316, 317, 319, 320, 321, 331, 332, 342, 346, 347, 349, 350, 352, 355, 356, 359, 361, 362, 365, 367, 371, 372, 374, 375, 378, 379, 380, 381, 382, 390, 396, 398, 399, 402, 407, 412, 415, 420, 422, 428, 429, 437, 438, 441, 443, 447, 448, 450, 451, 452, 455, 456, 457, 458, 459, 460, 461, 462, 463, 467, 468, 470, 473, 476, 477, 478, 479, 483, 485, 486, 495, 497, 504, 507, 509, 511], NumPruned=52224]
193800 parameters will be pruned
-------------

2023-05-31 16:19:53.114 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.26.conv (Conv2d(308, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 2, 7, 16, 18, 20, 22, 23, 24, 26, 28, 29, 31, 32, 35, 38, 39, 40, 42, 48, 49, 55, 65, 68, 69, 71, 75, 76, 80, 81, 82, 85, 89, 91, 92, 93, 95, 97, 99, 100, 103, 104, 107, 109, 111, 116, 118, 119, 124, 126, 131, 132, 135, 139, 141, 142, 145, 147, 150, 153, 155, 157, 162, 164, 165, 167, 169, 170, 172, 173, 174, 176, 177, 182, 183, 184, 190, 192, 194, 201, 202, 203, 210, 213, 214, 216, 219, 220, 223, 225, 234, 236, 238, 239, 242, 244, 246, 248, 249, 251, 252, 255], NumPruned=31416]
[ <DEP: prune_conv => prune_batchnorm on model.26.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 7, 16, 18, 20, 22, 23, 24, 26, 28, 29, 31, 32, 35, 38, 39, 40, 42, 48, 49, 55, 65, 68, 69, 71, 75, 76, 80, 81, 82, 85, 89, 91, 92, 93, 95, 97, 99, 100, 103, 104, 107, 109, 111, 116, 118, 119, 124, 126, 131, 132, 135, 139, 141, 142, 145, 147, 150, 153, 155, 157, 162, 164, 165, 167, 169, 170, 172, 173, 174, 176, 177, 182, 183, 184, 190, 192, 194, 201, 202, 203, 210, 213, 214, 216, 219, 220, 223, 225, 234, 236, 238, 239, 242, 244, 246, 248, 249, 251, 252, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 7, 16, 18, 20, 22, 23, 24, 26, 28, 29, 31, 32, 35, 38, 39, 40, 42, 48, 49, 55, 65, 68, 69, 71, 75, 76, 80, 81, 82, 85, 89, 91, 92, 93, 95, 97, 99, 100, 103, 104, 107, 109, 111, 116, 118, 119, 124, 126, 131, 132, 135, 139, 141, 142, 145, 147, 150, 153, 155, 157, 162, 164, 165, 167, 169, 170, 172, 173, 174, 176, 177, 182, 183, 184, 190, 192, 194, 201, 202, 203, 210, 213, 214, 216, 219, 220, 223, 225, 234, 236, 238, 239, 242, 244, 246, 248, 249, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512])>, Index=[257, 258, 263, 272, 274, 276, 278, 279, 280, 282, 284, 285, 287, 288, 291, 294, 295, 296, 298, 304, 305, 311, 321, 324, 325, 327, 331, 332, 336, 337, 338, 341, 345, 347, 348, 349, 351, 353, 355, 356, 359, 360, 363, 365, 367, 372, 374, 375, 380, 382, 387, 388, 391, 395, 397, 398, 401, 403, 406, 409, 411, 413, 418, 420, 421, 423, 425, 426, 428, 429, 430, 432, 433, 438, 439, 440, 446, 448, 450, 457, 458, 459, 466, 469, 470, 472, 475, 476, 479, 481, 490, 492, 494, 495, 498, 500, 502, 504, 505, 507, 508, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 263, 272, 274, 276, 278, 279, 280, 282, 284, 285, 287, 288, 291, 294, 295, 296, 298, 304, 305, 311, 321, 324, 325, 327, 331, 332, 336, 337, 338, 341, 345, 347, 348, 349, 351, 353, 355, 356, 359, 360, 363, 365, 367, 372, 374, 375, 380, 382, 387, 388, 391, 395, 397, 398, 401, 403, 406, 409, 411, 413, 418, 420, 421, 423, 425, 426, 428, 429, 430, 432, 433, 438, 439, 440, 446, 448, 450, 457, 458, 459, 466, 469, 470, 472, 475, 476, 479, 481, 490, 492, 494, 495, 498, 500, 502, 504, 505, 507, 508, 511], NumPruned=26112]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[257, 258, 263, 272, 274, 276, 278, 279, 280, 282, 284, 285, 287, 288, 291, 294, 295, 296, 298, 304, 305, 311, 321, 324, 325, 327, 331, 332, 336, 337, 338, 341, 345, 347, 348, 349, 351, 353, 355, 356, 359, 360, 363, 365, 367, 372, 374, 375, 380, 382, 387, 388, 391, 395, 397, 398, 401, 403, 406, 409, 411, 413, 418, 420, 421, 423, 425, 426, 428, 429, 430, 432, 433, 438, 439, 440, 446, 448, 450, 457, 458, 459, 466, 469, 470, 472, 475, 476, 479, 481, 490, 492, 494, 495, 498, 500, 502, 504, 505, 507, 508, 511], NumPruned=26112]
83844 parameters will be pruned
-------------

2023-05-31 16:19:53.116 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.27.conv (Conv2d(308, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 12, 17, 18, 24, 26, 31, 32, 33, 37, 44, 45, 46, 48, 49, 50, 51, 56, 57, 59, 61, 64, 67, 70, 74, 78, 80, 81, 89, 93, 94, 96, 97, 98, 103, 107, 109, 111, 112, 113, 116, 121, 125, 127, 129, 131, 135, 136, 141, 142, 143, 145, 150, 151, 154, 155, 156, 160, 162, 169, 170, 175, 177, 178, 184, 187, 190, 191, 192, 194, 195, 198, 199, 201, 205, 207, 208, 209, 216, 217, 222, 227, 228, 229, 230, 231, 232, 233, 237, 239, 240, 241, 242, 244, 247, 250, 253, 254], NumPruned=31416]
[ <DEP: prune_conv => prune_batchnorm on model.27.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 12, 17, 18, 24, 26, 31, 32, 33, 37, 44, 45, 46, 48, 49, 50, 51, 56, 57, 59, 61, 64, 67, 70, 74, 78, 80, 81, 89, 93, 94, 96, 97, 98, 103, 107, 109, 111, 112, 113, 116, 121, 125, 127, 129, 131, 135, 136, 141, 142, 143, 145, 150, 151, 154, 155, 156, 160, 162, 169, 170, 175, 177, 178, 184, 187, 190, 191, 192, 194, 195, 198, 199, 201, 205, 207, 208, 209, 216, 217, 222, 227, 228, 229, 230, 231, 232, 233, 237, 239, 240, 241, 242, 244, 247, 250, 253, 254], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 12, 17, 18, 24, 26, 31, 32, 33, 37, 44, 45, 46, 48, 49, 50, 51, 56, 57, 59, 61, 64, 67, 70, 74, 78, 80, 81, 89, 93, 94, 96, 97, 98, 103, 107, 109, 111, 112, 113, 116, 121, 125, 127, 129, 131, 135, 136, 141, 142, 143, 145, 150, 151, 154, 155, 156, 160, 162, 169, 170, 175, 177, 178, 184, 187, 190, 191, 192, 194, 195, 198, 199, 201, 205, 207, 208, 209, 216, 217, 222, 227, 228, 229, 230, 231, 232, 233, 237, 239, 240, 241, 242, 244, 247, 250, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.28.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 12, 17, 18, 24, 26, 31, 32, 33, 37, 44, 45, 46, 48, 49, 50, 51, 56, 57, 59, 61, 64, 67, 70, 74, 78, 80, 81, 89, 93, 94, 96, 97, 98, 103, 107, 109, 111, 112, 113, 116, 121, 125, 127, 129, 131, 135, 136, 141, 142, 143, 145, 150, 151, 154, 155, 156, 160, 162, 169, 170, 175, 177, 178, 184, 187, 190, 191, 192, 194, 195, 198, 199, 201, 205, 207, 208, 209, 216, 217, 222, 227, 228, 229, 230, 231, 232, 233, 237, 239, 240, 241, 242, 244, 247, 250, 253, 254], NumPruned=235008]
266628 parameters will be pruned
-------------

2023-05-31 16:19:53.118 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.28.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 3, 4, 15, 16, 17, 20, 25, 29, 30, 31, 36, 37, 42, 45, 48, 51, 53, 56, 60, 61, 63, 64, 65, 76, 82, 84, 86, 88, 91, 93, 95, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 120, 122, 123, 125, 131, 135, 137, 138, 141, 142, 146, 148, 149, 152, 153, 157, 160, 163, 164, 165, 167, 173, 175, 176, 180, 181, 184, 185, 186, 187, 191, 192, 196, 197, 202, 204, 206, 208, 212, 213, 215, 216, 217, 218, 220, 221, 222, 227, 236, 243, 245, 246, 247, 251, 252, 255], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.28.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 15, 16, 17, 20, 25, 29, 30, 31, 36, 37, 42, 45, 48, 51, 53, 56, 60, 61, 63, 64, 65, 76, 82, 84, 86, 88, 91, 93, 95, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 120, 122, 123, 125, 131, 135, 137, 138, 141, 142, 146, 148, 149, 152, 153, 157, 160, 163, 164, 165, 167, 173, 175, 176, 180, 181, 184, 185, 186, 187, 191, 192, 196, 197, 202, 204, 206, 208, 212, 213, 215, 216, 217, 218, 220, 221, 222, 227, 236, 243, 245, 246, 247, 251, 252, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 15, 16, 17, 20, 25, 29, 30, 31, 36, 37, 42, 45, 48, 51, 53, 56, 60, 61, 63, 64, 65, 76, 82, 84, 86, 88, 91, 93, 95, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 120, 122, 123, 125, 131, 135, 137, 138, 141, 142, 146, 148, 149, 152, 153, 157, 160, 163, 164, 165, 167, 173, 175, 176, 180, 181, 184, 185, 186, 187, 191, 192, 196, 197, 202, 204, 206, 208, 212, 213, 215, 216, 217, 218, 220, 221, 222, 227, 236, 243, 245, 246, 247, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 410])>, Index=[0, 3, 4, 15, 16, 17, 20, 25, 29, 30, 31, 36, 37, 42, 45, 48, 51, 53, 56, 60, 61, 63, 64, 65, 76, 82, 84, 86, 88, 91, 93, 95, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 120, 122, 123, 125, 131, 135, 137, 138, 141, 142, 146, 148, 149, 152, 153, 157, 160, 163, 164, 165, 167, 173, 175, 176, 180, 181, 184, 185, 186, 187, 191, 192, 196, 197, 202, 204, 206, 208, 212, 213, 215, 216, 217, 218, 220, 221, 222, 227, 236, 243, 245, 246, 247, 251, 252, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.31.conv (Conv2d(410, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 15, 16, 17, 20, 25, 29, 30, 31, 36, 37, 42, 45, 48, 51, 53, 56, 60, 61, 63, 64, 65, 76, 82, 84, 86, 88, 91, 93, 95, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 120, 122, 123, 125, 131, 135, 137, 138, 141, 142, 146, 148, 149, 152, 153, 157, 160, 163, 164, 165, 167, 173, 175, 176, 180, 181, 184, 185, 186, 187, 191, 192, 196, 197, 202, 204, 206, 208, 212, 213, 215, 216, 217, 218, 220, 221, 222, 227, 236, 243, 245, 246, 247, 251, 252, 255], NumPruned=26112]
[ <DEP: _prune_concat => prune_related_conv on model.30.conv (Conv2d(410, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 15, 16, 17, 20, 25, 29, 30, 31, 36, 37, 42, 45, 48, 51, 53, 56, 60, 61, 63, 64, 65, 76, 82, 84, 86, 88, 91, 93, 95, 99, 101, 102, 103, 104, 105, 107, 110, 111, 112, 113, 114, 115, 117, 120, 122, 123, 125, 131, 135, 137, 138, 141, 142, 146, 148, 149, 152, 153, 157, 160, 163, 164, 165, 167, 173, 175, 176, 180, 181, 184, 185, 186, 187, 191, 192, 196, 197, 202, 204, 206, 208, 212, 213, 215, 216, 217, 218, 220, 221, 222, 227, 236, 243, 245, 246, 247, 251, 252, 255], NumPruned=26112]
193800 parameters will be pruned
-------------

2023-05-31 16:19:53.120 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.30.conv (Conv2d(308, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[4, 7, 10, 13, 18, 23, 24, 28, 31, 38, 39, 41, 42, 45, 46, 48, 49, 50, 51, 52, 55, 56, 60, 64, 65, 71, 75, 76, 80, 87, 91, 93, 94, 96, 97, 99, 101, 105, 110, 115, 116, 117, 119, 120, 121, 124, 125, 130, 132, 134, 136, 137, 141, 143, 144, 145, 147, 149, 152, 155, 158, 162, 163, 164, 168, 172, 174, 176, 180, 185, 186, 187, 188, 189, 192, 194, 197, 199, 201, 202, 204, 205, 207, 209, 210, 212, 213, 214, 215, 216, 220, 230, 231, 235, 239, 240, 241, 243, 247, 251, 253, 254], NumPruned=31416]
[ <DEP: prune_conv => prune_batchnorm on model.30.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 7, 10, 13, 18, 23, 24, 28, 31, 38, 39, 41, 42, 45, 46, 48, 49, 50, 51, 52, 55, 56, 60, 64, 65, 71, 75, 76, 80, 87, 91, 93, 94, 96, 97, 99, 101, 105, 110, 115, 116, 117, 119, 120, 121, 124, 125, 130, 132, 134, 136, 137, 141, 143, 144, 145, 147, 149, 152, 155, 158, 162, 163, 164, 168, 172, 174, 176, 180, 185, 186, 187, 188, 189, 192, 194, 197, 199, 201, 202, 204, 205, 207, 209, 210, 212, 213, 214, 215, 216, 220, 230, 231, 235, 239, 240, 241, 243, 247, 251, 253, 254], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 7, 10, 13, 18, 23, 24, 28, 31, 38, 39, 41, 42, 45, 46, 48, 49, 50, 51, 52, 55, 56, 60, 64, 65, 71, 75, 76, 80, 87, 91, 93, 94, 96, 97, 99, 101, 105, 110, 115, 116, 117, 119, 120, 121, 124, 125, 130, 132, 134, 136, 137, 141, 143, 144, 145, 147, 149, 152, 155, 158, 162, 163, 164, 168, 172, 174, 176, 180, 185, 186, 187, 188, 189, 192, 194, 197, 199, 201, 202, 204, 205, 207, 209, 210, 212, 213, 214, 215, 216, 220, 230, 231, 235, 239, 240, 241, 243, 247, 251, 253, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024])>, Index=[772, 775, 778, 781, 786, 791, 792, 796, 799, 806, 807, 809, 810, 813, 814, 816, 817, 818, 819, 820, 823, 824, 828, 832, 833, 839, 843, 844, 848, 855, 859, 861, 862, 864, 865, 867, 869, 873, 878, 883, 884, 885, 887, 888, 889, 892, 893, 898, 900, 902, 904, 905, 909, 911, 912, 913, 915, 917, 920, 923, 926, 930, 931, 932, 936, 940, 942, 944, 948, 953, 954, 955, 956, 957, 960, 962, 965, 967, 969, 970, 972, 973, 975, 977, 978, 980, 981, 982, 983, 984, 988, 998, 999, 1003, 1007, 1008, 1009, 1011, 1015, 1019, 1021, 1022], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[772, 775, 778, 781, 786, 791, 792, 796, 799, 806, 807, 809, 810, 813, 814, 816, 817, 818, 819, 820, 823, 824, 828, 832, 833, 839, 843, 844, 848, 855, 859, 861, 862, 864, 865, 867, 869, 873, 878, 883, 884, 885, 887, 888, 889, 892, 893, 898, 900, 902, 904, 905, 909, 911, 912, 913, 915, 917, 920, 923, 926, 930, 931, 932, 936, 940, 942, 944, 948, 953, 954, 955, 956, 957, 960, 962, 965, 967, 969, 970, 972, 973, 975, 977, 978, 980, 981, 982, 983, 984, 988, 998, 999, 1003, 1007, 1008, 1009, 1011, 1015, 1019, 1021, 1022], NumPruned=104448]
136068 parameters will be pruned
-------------

2023-05-31 16:19:53.123 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.31.conv (Conv2d(308, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 8, 9, 10, 11, 14, 15, 25, 26, 27, 28, 33, 37, 42, 44, 47, 50, 51, 55, 57, 58, 63, 66, 71, 73, 74, 76, 77, 78, 80, 83, 87, 88, 90, 92, 93, 95, 102, 103, 104, 106, 107, 108, 109, 111, 113, 115, 117, 119, 120, 121, 124, 125, 126, 127, 133, 134, 138, 139, 140, 142, 143, 149, 150, 151, 153, 155, 161, 162, 166, 173, 179, 182, 183, 186, 191, 192, 194, 195, 196, 198, 199, 200, 202, 207, 210, 211, 212, 213, 214, 215, 220, 228, 235, 237, 238, 241, 243, 246, 253], NumPruned=31416]
[ <DEP: prune_conv => prune_batchnorm on model.31.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 8, 9, 10, 11, 14, 15, 25, 26, 27, 28, 33, 37, 42, 44, 47, 50, 51, 55, 57, 58, 63, 66, 71, 73, 74, 76, 77, 78, 80, 83, 87, 88, 90, 92, 93, 95, 102, 103, 104, 106, 107, 108, 109, 111, 113, 115, 117, 119, 120, 121, 124, 125, 126, 127, 133, 134, 138, 139, 140, 142, 143, 149, 150, 151, 153, 155, 161, 162, 166, 173, 179, 182, 183, 186, 191, 192, 194, 195, 196, 198, 199, 200, 202, 207, 210, 211, 212, 213, 214, 215, 220, 228, 235, 237, 238, 241, 243, 246, 253], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 8, 9, 10, 11, 14, 15, 25, 26, 27, 28, 33, 37, 42, 44, 47, 50, 51, 55, 57, 58, 63, 66, 71, 73, 74, 76, 77, 78, 80, 83, 87, 88, 90, 92, 93, 95, 102, 103, 104, 106, 107, 108, 109, 111, 113, 115, 117, 119, 120, 121, 124, 125, 126, 127, 133, 134, 138, 139, 140, 142, 143, 149, 150, 151, 153, 155, 161, 162, 166, 173, 179, 182, 183, 186, 191, 192, 194, 195, 196, 198, 199, 200, 202, 207, 210, 211, 212, 213, 214, 215, 220, 228, 235, 237, 238, 241, 243, 246, 253], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.32.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 8, 9, 10, 11, 14, 15, 25, 26, 27, 28, 33, 37, 42, 44, 47, 50, 51, 55, 57, 58, 63, 66, 71, 73, 74, 76, 77, 78, 80, 83, 87, 88, 90, 92, 93, 95, 102, 103, 104, 106, 107, 108, 109, 111, 113, 115, 117, 119, 120, 121, 124, 125, 126, 127, 133, 134, 138, 139, 140, 142, 143, 149, 150, 151, 153, 155, 161, 162, 166, 173, 179, 182, 183, 186, 191, 192, 194, 195, 196, 198, 199, 200, 202, 207, 210, 211, 212, 213, 214, 215, 220, 228, 235, 237, 238, 241, 243, 246, 253], NumPruned=235008]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 922])>, Index=[512, 514, 515, 520, 521, 522, 523, 526, 527, 537, 538, 539, 540, 545, 549, 554, 556, 559, 562, 563, 567, 569, 570, 575, 578, 583, 585, 586, 588, 589, 590, 592, 595, 599, 600, 602, 604, 605, 607, 614, 615, 616, 618, 619, 620, 621, 623, 625, 627, 629, 631, 632, 633, 636, 637, 638, 639, 645, 646, 650, 651, 652, 654, 655, 661, 662, 663, 665, 667, 673, 674, 678, 685, 691, 694, 695, 698, 703, 704, 706, 707, 708, 710, 711, 712, 714, 719, 722, 723, 724, 725, 726, 727, 732, 740, 747, 749, 750, 753, 755, 758, 765], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(922, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 514, 515, 520, 521, 522, 523, 526, 527, 537, 538, 539, 540, 545, 549, 554, 556, 559, 562, 563, 567, 569, 570, 575, 578, 583, 585, 586, 588, 589, 590, 592, 595, 599, 600, 602, 604, 605, 607, 614, 615, 616, 618, 619, 620, 621, 623, 625, 627, 629, 631, 632, 633, 636, 637, 638, 639, 645, 646, 650, 651, 652, 654, 655, 661, 662, 663, 665, 667, 673, 674, 678, 685, 691, 694, 695, 698, 703, 704, 706, 707, 708, 710, 711, 712, 714, 719, 722, 723, 724, 725, 726, 727, 732, 740, 747, 749, 750, 753, 755, 758, 765], NumPruned=104448]
371076 parameters will be pruned
-------------

2023-05-31 16:19:53.129 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.32.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 16, 20, 21, 22, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 49, 52, 53, 54, 55, 61, 62, 65, 69, 73, 74, 78, 79, 82, 85, 86, 88, 90, 93, 97, 98, 99, 100, 104, 106, 107, 111, 112, 113, 115, 116, 120, 122, 123, 126, 128, 131, 136, 137, 139, 140, 143, 145, 146, 150, 151, 159, 162, 165, 167, 176, 184, 186, 188, 190, 192, 193, 194, 195, 202, 203, 204, 207, 211, 213, 216, 219, 221, 223, 225, 230, 232, 237, 241, 242, 245, 247, 248, 251, 252, 254, 255], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.32.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 16, 20, 21, 22, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 49, 52, 53, 54, 55, 61, 62, 65, 69, 73, 74, 78, 79, 82, 85, 86, 88, 90, 93, 97, 98, 99, 100, 104, 106, 107, 111, 112, 113, 115, 116, 120, 122, 123, 126, 128, 131, 136, 137, 139, 140, 143, 145, 146, 150, 151, 159, 162, 165, 167, 176, 184, 186, 188, 190, 192, 193, 194, 195, 202, 203, 204, 207, 211, 213, 216, 219, 221, 223, 225, 230, 232, 237, 241, 242, 245, 247, 248, 251, 252, 254, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 16, 20, 21, 22, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 49, 52, 53, 54, 55, 61, 62, 65, 69, 73, 74, 78, 79, 82, 85, 86, 88, 90, 93, 97, 98, 99, 100, 104, 106, 107, 111, 112, 113, 115, 116, 120, 122, 123, 126, 128, 131, 136, 137, 139, 140, 143, 145, 146, 150, 151, 159, 162, 165, 167, 176, 184, 186, 188, 190, 192, 193, 194, 195, 202, 203, 204, 207, 211, 213, 216, 219, 221, 223, 225, 230, 232, 237, 241, 242, 245, 247, 248, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.33.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 16, 20, 21, 22, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 46, 49, 52, 53, 54, 55, 61, 62, 65, 69, 73, 74, 78, 79, 82, 85, 86, 88, 90, 93, 97, 98, 99, 100, 104, 106, 107, 111, 112, 113, 115, 116, 120, 122, 123, 126, 128, 131, 136, 137, 139, 140, 143, 145, 146, 150, 151, 159, 162, 165, 167, 176, 184, 186, 188, 190, 192, 193, 194, 195, 202, 203, 204, 207, 211, 213, 216, 219, 221, 223, 225, 230, 232, 237, 241, 242, 245, 247, 248, 251, 252, 254, 255], NumPruned=235008]
376584 parameters will be pruned
-------------

2023-05-31 16:19:53.132 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.33.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 9, 10, 11, 13, 17, 18, 19, 21, 23, 24, 29, 34, 36, 37, 43, 47, 49, 52, 54, 60, 65, 66, 67, 69, 70, 73, 74, 77, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 94, 97, 99, 100, 105, 106, 108, 112, 113, 119, 121, 122, 123, 124, 126, 127, 132, 134, 135, 136, 138, 139, 143, 144, 146, 151, 155, 158, 159, 163, 164, 165, 167, 170, 171, 175, 176, 180, 182, 188, 196, 200, 201, 206, 211, 212, 213, 214, 217, 218, 219, 224, 225, 227, 231, 232, 234, 238, 243, 246, 251, 253], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.33.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 9, 10, 11, 13, 17, 18, 19, 21, 23, 24, 29, 34, 36, 37, 43, 47, 49, 52, 54, 60, 65, 66, 67, 69, 70, 73, 74, 77, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 94, 97, 99, 100, 105, 106, 108, 112, 113, 119, 121, 122, 123, 124, 126, 127, 132, 134, 135, 136, 138, 139, 143, 144, 146, 151, 155, 158, 159, 163, 164, 165, 167, 170, 171, 175, 176, 180, 182, 188, 196, 200, 201, 206, 211, 212, 213, 214, 217, 218, 219, 224, 225, 227, 231, 232, 234, 238, 243, 246, 251, 253], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 9, 10, 11, 13, 17, 18, 19, 21, 23, 24, 29, 34, 36, 37, 43, 47, 49, 52, 54, 60, 65, 66, 67, 69, 70, 73, 74, 77, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 94, 97, 99, 100, 105, 106, 108, 112, 113, 119, 121, 122, 123, 124, 126, 127, 132, 134, 135, 136, 138, 139, 143, 144, 146, 151, 155, 158, 159, 163, 164, 165, 167, 170, 171, 175, 176, 180, 182, 188, 196, 200, 201, 206, 211, 212, 213, 214, 217, 218, 219, 224, 225, 227, 231, 232, 234, 238, 243, 246, 251, 253], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.34.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 9, 10, 11, 13, 17, 18, 19, 21, 23, 24, 29, 34, 36, 37, 43, 47, 49, 52, 54, 60, 65, 66, 67, 69, 70, 73, 74, 77, 79, 80, 81, 82, 84, 87, 88, 89, 90, 91, 94, 97, 99, 100, 105, 106, 108, 112, 113, 119, 121, 122, 123, 124, 126, 127, 132, 134, 135, 136, 138, 139, 143, 144, 146, 151, 155, 158, 159, 163, 164, 165, 167, 170, 171, 175, 176, 180, 182, 188, 196, 200, 201, 206, 211, 212, 213, 214, 217, 218, 219, 224, 225, 227, 231, 232, 234, 238, 243, 246, 251, 253], NumPruned=235008]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 666, 820])>, Index=[256, 257, 265, 266, 267, 269, 273, 274, 275, 277, 279, 280, 285, 290, 292, 293, 299, 303, 305, 308, 310, 316, 321, 322, 323, 325, 326, 329, 330, 333, 335, 336, 337, 338, 340, 343, 344, 345, 346, 347, 350, 353, 355, 356, 361, 362, 364, 368, 369, 375, 377, 378, 379, 380, 382, 383, 388, 390, 391, 392, 394, 395, 399, 400, 402, 407, 411, 414, 415, 419, 420, 421, 423, 426, 427, 431, 432, 436, 438, 444, 452, 456, 457, 462, 467, 468, 469, 470, 473, 474, 475, 480, 481, 483, 487, 488, 490, 494, 499, 502, 507, 509], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(820, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[256, 257, 265, 266, 267, 269, 273, 274, 275, 277, 279, 280, 285, 290, 292, 293, 299, 303, 305, 308, 310, 316, 321, 322, 323, 325, 326, 329, 330, 333, 335, 336, 337, 338, 340, 343, 344, 345, 346, 347, 350, 353, 355, 356, 361, 362, 364, 368, 369, 375, 377, 378, 379, 380, 382, 383, 388, 390, 391, 392, 394, 395, 399, 400, 402, 407, 411, 414, 415, 419, 420, 421, 423, 426, 427, 431, 432, 436, 438, 444, 452, 456, 457, 462, 467, 468, 469, 470, 473, 474, 475, 480, 481, 483, 487, 488, 490, 494, 499, 502, 507, 509], NumPruned=104448]
481032 parameters will be pruned
-------------

2023-05-31 16:19:53.137 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.34.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 5, 6, 8, 9, 13, 17, 22, 24, 25, 29, 31, 33, 34, 37, 41, 45, 46, 47, 48, 50, 51, 53, 54, 55, 62, 63, 66, 67, 71, 74, 77, 78, 79, 82, 83, 84, 91, 94, 95, 96, 97, 98, 100, 105, 106, 107, 111, 114, 117, 123, 126, 128, 130, 132, 136, 141, 146, 148, 149, 150, 154, 160, 163, 164, 166, 167, 168, 169, 176, 178, 181, 182, 185, 191, 192, 196, 197, 199, 203, 206, 207, 208, 212, 213, 214, 219, 221, 223, 224, 225, 229, 233, 236, 243, 245, 247, 248, 249, 251, 252, 253], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.34.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 5, 6, 8, 9, 13, 17, 22, 24, 25, 29, 31, 33, 34, 37, 41, 45, 46, 47, 48, 50, 51, 53, 54, 55, 62, 63, 66, 67, 71, 74, 77, 78, 79, 82, 83, 84, 91, 94, 95, 96, 97, 98, 100, 105, 106, 107, 111, 114, 117, 123, 126, 128, 130, 132, 136, 141, 146, 148, 149, 150, 154, 160, 163, 164, 166, 167, 168, 169, 176, 178, 181, 182, 185, 191, 192, 196, 197, 199, 203, 206, 207, 208, 212, 213, 214, 219, 221, 223, 224, 225, 229, 233, 236, 243, 245, 247, 248, 249, 251, 252, 253], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 5, 6, 8, 9, 13, 17, 22, 24, 25, 29, 31, 33, 34, 37, 41, 45, 46, 47, 48, 50, 51, 53, 54, 55, 62, 63, 66, 67, 71, 74, 77, 78, 79, 82, 83, 84, 91, 94, 95, 96, 97, 98, 100, 105, 106, 107, 111, 114, 117, 123, 126, 128, 130, 132, 136, 141, 146, 148, 149, 150, 154, 160, 163, 164, 166, 167, 168, 169, 176, 178, 181, 182, 185, 191, 192, 196, 197, 199, 203, 206, 207, 208, 212, 213, 214, 219, 221, 223, 224, 225, 229, 233, 236, 243, 245, 247, 248, 249, 251, 252, 253], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.35.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 5, 6, 8, 9, 13, 17, 22, 24, 25, 29, 31, 33, 34, 37, 41, 45, 46, 47, 48, 50, 51, 53, 54, 55, 62, 63, 66, 67, 71, 74, 77, 78, 79, 82, 83, 84, 91, 94, 95, 96, 97, 98, 100, 105, 106, 107, 111, 114, 117, 123, 126, 128, 130, 132, 136, 141, 146, 148, 149, 150, 154, 160, 163, 164, 166, 167, 168, 169, 176, 178, 181, 182, 185, 191, 192, 196, 197, 199, 203, 206, 207, 208, 212, 213, 214, 219, 221, 223, 224, 225, 229, 233, 236, 243, 245, 247, 248, 249, 251, 252, 253], NumPruned=235008]
376584 parameters will be pruned
-------------

2023-05-31 16:19:53.140 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.35.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[8, 9, 10, 15, 19, 22, 24, 32, 35, 36, 37, 38, 44, 47, 49, 50, 55, 57, 58, 59, 62, 66, 67, 73, 76, 78, 80, 85, 87, 89, 93, 96, 97, 99, 100, 103, 104, 106, 113, 116, 121, 127, 128, 129, 131, 133, 134, 141, 143, 145, 147, 148, 149, 155, 156, 161, 162, 163, 164, 168, 171, 173, 176, 177, 179, 181, 184, 188, 190, 195, 197, 200, 203, 205, 208, 210, 212, 216, 217, 220, 221, 222, 225, 226, 227, 228, 229, 230, 232, 234, 235, 239, 240, 241, 243, 244, 248, 249, 251, 252, 254, 255], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.35.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[8, 9, 10, 15, 19, 22, 24, 32, 35, 36, 37, 38, 44, 47, 49, 50, 55, 57, 58, 59, 62, 66, 67, 73, 76, 78, 80, 85, 87, 89, 93, 96, 97, 99, 100, 103, 104, 106, 113, 116, 121, 127, 128, 129, 131, 133, 134, 141, 143, 145, 147, 148, 149, 155, 156, 161, 162, 163, 164, 168, 171, 173, 176, 177, 179, 181, 184, 188, 190, 195, 197, 200, 203, 205, 208, 210, 212, 216, 217, 220, 221, 222, 225, 226, 227, 228, 229, 230, 232, 234, 235, 239, 240, 241, 243, 244, 248, 249, 251, 252, 254, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[8, 9, 10, 15, 19, 22, 24, 32, 35, 36, 37, 38, 44, 47, 49, 50, 55, 57, 58, 59, 62, 66, 67, 73, 76, 78, 80, 85, 87, 89, 93, 96, 97, 99, 100, 103, 104, 106, 113, 116, 121, 127, 128, 129, 131, 133, 134, 141, 143, 145, 147, 148, 149, 155, 156, 161, 162, 163, 164, 168, 171, 173, 176, 177, 179, 181, 184, 188, 190, 195, 197, 200, 203, 205, 208, 210, 212, 216, 217, 220, 221, 222, 225, 226, 227, 228, 229, 230, 232, 234, 235, 239, 240, 241, 243, 244, 248, 249, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 410, 564, 718])>, Index=[8, 9, 10, 15, 19, 22, 24, 32, 35, 36, 37, 38, 44, 47, 49, 50, 55, 57, 58, 59, 62, 66, 67, 73, 76, 78, 80, 85, 87, 89, 93, 96, 97, 99, 100, 103, 104, 106, 113, 116, 121, 127, 128, 129, 131, 133, 134, 141, 143, 145, 147, 148, 149, 155, 156, 161, 162, 163, 164, 168, 171, 173, 176, 177, 179, 181, 184, 188, 190, 195, 197, 200, 203, 205, 208, 210, 212, 216, 217, 220, 221, 222, 225, 226, 227, 228, 229, 230, 232, 234, 235, 239, 240, 241, 243, 244, 248, 249, 251, 252, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.37.conv (Conv2d(718, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[8, 9, 10, 15, 19, 22, 24, 32, 35, 36, 37, 38, 44, 47, 49, 50, 55, 57, 58, 59, 62, 66, 67, 73, 76, 78, 80, 85, 87, 89, 93, 96, 97, 99, 100, 103, 104, 106, 113, 116, 121, 127, 128, 129, 131, 133, 134, 141, 143, 145, 147, 148, 149, 155, 156, 161, 162, 163, 164, 168, 171, 173, 176, 177, 179, 181, 184, 188, 190, 195, 197, 200, 203, 205, 208, 210, 212, 216, 217, 220, 221, 222, 225, 226, 227, 228, 229, 230, 232, 234, 235, 239, 240, 241, 243, 244, 248, 249, 251, 252, 254, 255], NumPruned=104448]
246024 parameters will be pruned
-------------

2023-05-31 16:19:53.143 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.37.conv (Conv2d(616, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=251944]
[ <DEP: prune_conv => prune_batchnorm on model.37.bn (BatchNorm2d(1024, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=818]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.54.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=104704]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.40.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=209408]
[ <DEP: _prune_elementwise_op => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.39.conv (Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 3, 4, 5, 7, 9, 11, 15, 16, 17, 23, 24, 25, 26, 28, 33, 37, 39, 40, 47, 49, 50, 53, 54, 61, 63, 65, 69, 70, 71, 72, 73, 79, 81, 83, 85, 86, 89, 91, 101, 103, 109, 110, 111, 112, 113, 115, 120, 123, 126, 127, 130, 131, 139, 140, 141, 145, 150, 152, 153, 155, 163, 165, 169, 170, 172, 177, 178, 180, 190, 192, 193, 195, 196, 198, 199, 200, 203, 204, 205, 207, 210, 211, 212, 214, 215, 216, 222, 223, 224, 227, 229, 230, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 251, 253, 255, 260, 268, 273, 274, 278, 287, 290, 292, 295, 301, 303, 304, 310, 311, 320, 321, 323, 324, 326, 330, 333, 334, 335, 336, 338, 340, 350, 356, 357, 359, 360, 365, 368, 369, 371, 372, 374, 375, 376, 378, 384, 386, 387, 389, 390, 394, 397, 398, 399, 401, 402, 404, 406, 407, 410, 417, 420, 423, 424, 429, 430, 435, 436, 440, 441, 444, 445, 451, 452, 455, 458, 460, 461, 464, 466, 468, 469, 472, 473, 475, 476, 478, 484, 486, 489, 491, 492, 494, 498, 499, 503, 506, 510, 515, 516, 517, 519, 520, 526, 527, 528, 531, 533, 534, 538, 539, 540, 542, 543, 544, 551, 553, 554, 555, 557, 560, 562, 564, 565, 566, 569, 570, 576, 580, 581, 584, 585, 587, 597, 599, 610, 612, 615, 619, 622, 623, 624, 628, 629, 631, 632, 635, 637, 641, 646, 647, 648, 652, 653, 658, 660, 661, 662, 665, 667, 668, 670, 671, 672, 673, 674, 675, 676, 680, 682, 683, 685, 686, 687, 688, 689, 691, 693, 695, 696, 698, 700, 702, 703, 704, 706, 707, 709, 711, 714, 715, 716, 719, 721, 722, 732, 733, 734, 736, 737, 741, 744, 747, 752, 756, 762, 763, 765, 766, 768, 770, 771, 772, 774, 775, 777, 778, 780, 781, 783, 784, 786, 792, 793, 795, 796, 798, 799, 803, 804, 806, 807, 809, 810, 811, 812, 814, 822, 825, 826, 827, 838, 843, 845, 850, 855, 858, 859, 861, 868, 870, 880, 885, 886, 888, 894, 900, 902, 903, 904, 905, 907, 908, 914, 915, 916, 918, 924, 926, 927, 928, 929, 932, 934, 938, 939, 941, 946, 947, 950, 953, 954, 961, 962, 967, 971, 974, 975, 976, 980, 981, 984, 986, 988, 990, 991, 994, 1002, 1004, 1005, 1008, 1015, 1016, 1019, 1022], NumPruned=209408]
776282 parameters will be pruned
-------------

2023-05-31 16:19:53.149 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.39.conv (Conv2d(615, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[2, 6, 9, 10, 11, 14, 17, 20, 23, 28, 32, 34, 36, 39, 41, 42, 45, 47, 54, 55, 57, 58, 61, 64, 65, 67, 69, 70, 71, 73, 75, 76, 78, 85, 86, 89, 92, 95, 98, 104, 107, 111, 112, 114, 117, 121, 122, 125, 126, 129, 130, 131, 132, 134, 137, 140, 141, 148, 149, 152, 154, 158, 162, 167, 174, 176, 181, 182, 183, 187, 190, 191, 194, 195, 196, 197, 199, 200, 201, 206, 208, 209, 214, 215, 216, 219, 223, 227, 229, 233, 236, 239, 240, 241, 247, 248, 251, 253, 257, 258, 259, 260, 262, 266, 269, 271, 274, 275, 276, 278, 282, 283, 284, 288, 293, 294, 297, 299, 303, 305, 306, 307, 309, 310, 311, 313, 314, 316, 318, 321, 330, 331, 333, 335, 340, 343, 344, 348, 352, 354, 355, 356, 357, 359, 363, 368, 370, 371, 372, 376, 381, 382, 384, 386, 387, 390, 391, 392, 394, 396, 398, 399, 400, 401, 403, 404, 405, 407, 408, 413, 415, 418, 419, 420, 424, 425, 429, 433, 446, 452, 456, 460, 462, 463, 465, 466, 467, 468, 469, 473, 475, 477, 482, 484, 486, 487, 488, 491, 495, 499, 500, 504, 510, 511], NumPruned=125460]
[ <DEP: prune_conv => prune_batchnorm on model.39.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 6, 9, 10, 11, 14, 17, 20, 23, 28, 32, 34, 36, 39, 41, 42, 45, 47, 54, 55, 57, 58, 61, 64, 65, 67, 69, 70, 71, 73, 75, 76, 78, 85, 86, 89, 92, 95, 98, 104, 107, 111, 112, 114, 117, 121, 122, 125, 126, 129, 130, 131, 132, 134, 137, 140, 141, 148, 149, 152, 154, 158, 162, 167, 174, 176, 181, 182, 183, 187, 190, 191, 194, 195, 196, 197, 199, 200, 201, 206, 208, 209, 214, 215, 216, 219, 223, 227, 229, 233, 236, 239, 240, 241, 247, 248, 251, 253, 257, 258, 259, 260, 262, 266, 269, 271, 274, 275, 276, 278, 282, 283, 284, 288, 293, 294, 297, 299, 303, 305, 306, 307, 309, 310, 311, 313, 314, 316, 318, 321, 330, 331, 333, 335, 340, 343, 344, 348, 352, 354, 355, 356, 357, 359, 363, 368, 370, 371, 372, 376, 381, 382, 384, 386, 387, 390, 391, 392, 394, 396, 398, 399, 400, 401, 403, 404, 405, 407, 408, 413, 415, 418, 419, 420, 424, 425, 429, 433, 446, 452, 456, 460, 462, 463, 465, 466, 467, 468, 469, 473, 475, 477, 482, 484, 486, 487, 488, 491, 495, 499, 500, 504, 510, 511], NumPruned=408]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 6, 9, 10, 11, 14, 17, 20, 23, 28, 32, 34, 36, 39, 41, 42, 45, 47, 54, 55, 57, 58, 61, 64, 65, 67, 69, 70, 71, 73, 75, 76, 78, 85, 86, 89, 92, 95, 98, 104, 107, 111, 112, 114, 117, 121, 122, 125, 126, 129, 130, 131, 132, 134, 137, 140, 141, 148, 149, 152, 154, 158, 162, 167, 174, 176, 181, 182, 183, 187, 190, 191, 194, 195, 196, 197, 199, 200, 201, 206, 208, 209, 214, 215, 216, 219, 223, 227, 229, 233, 236, 239, 240, 241, 247, 248, 251, 253, 257, 258, 259, 260, 262, 266, 269, 271, 274, 275, 276, 278, 282, 283, 284, 288, 293, 294, 297, 299, 303, 305, 306, 307, 309, 310, 311, 313, 314, 316, 318, 321, 330, 331, 333, 335, 340, 343, 344, 348, 352, 354, 355, 356, 357, 359, 363, 368, 370, 371, 372, 376, 381, 382, 384, 386, 387, 390, 391, 392, 394, 396, 398, 399, 400, 401, 403, 404, 405, 407, 408, 413, 415, 418, 419, 420, 424, 425, 429, 433, 446, 452, 456, 460, 462, 463, 465, 466, 467, 468, 469, 473, 475, 477, 482, 484, 486, 487, 488, 491, 495, 499, 500, 504, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 1024])>, Index=[514, 518, 521, 522, 523, 526, 529, 532, 535, 540, 544, 546, 548, 551, 553, 554, 557, 559, 566, 567, 569, 570, 573, 576, 577, 579, 581, 582, 583, 585, 587, 588, 590, 597, 598, 601, 604, 607, 610, 616, 619, 623, 624, 626, 629, 633, 634, 637, 638, 641, 642, 643, 644, 646, 649, 652, 653, 660, 661, 664, 666, 670, 674, 679, 686, 688, 693, 694, 695, 699, 702, 703, 706, 707, 708, 709, 711, 712, 713, 718, 720, 721, 726, 727, 728, 731, 735, 739, 741, 745, 748, 751, 752, 753, 759, 760, 763, 765, 769, 770, 771, 772, 774, 778, 781, 783, 786, 787, 788, 790, 794, 795, 796, 800, 805, 806, 809, 811, 815, 817, 818, 819, 821, 822, 823, 825, 826, 828, 830, 833, 842, 843, 845, 847, 852, 855, 856, 860, 864, 866, 867, 868, 869, 871, 875, 880, 882, 883, 884, 888, 893, 894, 896, 898, 899, 902, 903, 904, 906, 908, 910, 911, 912, 913, 915, 916, 917, 919, 920, 925, 927, 930, 931, 932, 936, 937, 941, 945, 958, 964, 968, 972, 974, 975, 977, 978, 979, 980, 981, 985, 987, 989, 994, 996, 998, 999, 1000, 1003, 1007, 1011, 1012, 1016, 1022, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[514, 518, 521, 522, 523, 526, 529, 532, 535, 540, 544, 546, 548, 551, 553, 554, 557, 559, 566, 567, 569, 570, 573, 576, 577, 579, 581, 582, 583, 585, 587, 588, 590, 597, 598, 601, 604, 607, 610, 616, 619, 623, 624, 626, 629, 633, 634, 637, 638, 641, 642, 643, 644, 646, 649, 652, 653, 660, 661, 664, 666, 670, 674, 679, 686, 688, 693, 694, 695, 699, 702, 703, 706, 707, 708, 709, 711, 712, 713, 718, 720, 721, 726, 727, 728, 731, 735, 739, 741, 745, 748, 751, 752, 753, 759, 760, 763, 765, 769, 770, 771, 772, 774, 778, 781, 783, 786, 787, 788, 790, 794, 795, 796, 800, 805, 806, 809, 811, 815, 817, 818, 819, 821, 822, 823, 825, 826, 828, 830, 833, 842, 843, 845, 847, 852, 855, 856, 860, 864, 866, 867, 868, 869, 871, 875, 880, 882, 883, 884, 888, 893, 894, 896, 898, 899, 902, 903, 904, 906, 908, 910, 911, 912, 913, 915, 916, 917, 919, 920, 925, 927, 930, 931, 932, 936, 937, 941, 945, 958, 964, 968, 972, 974, 975, 977, 978, 979, 980, 981, 985, 987, 989, 994, 996, 998, 999, 1000, 1003, 1007, 1011, 1012, 1016, 1022, 1023], NumPruned=52224]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[514, 518, 521, 522, 523, 526, 529, 532, 535, 540, 544, 546, 548, 551, 553, 554, 557, 559, 566, 567, 569, 570, 573, 576, 577, 579, 581, 582, 583, 585, 587, 588, 590, 597, 598, 601, 604, 607, 610, 616, 619, 623, 624, 626, 629, 633, 634, 637, 638, 641, 642, 643, 644, 646, 649, 652, 653, 660, 661, 664, 666, 670, 674, 679, 686, 688, 693, 694, 695, 699, 702, 703, 706, 707, 708, 709, 711, 712, 713, 718, 720, 721, 726, 727, 728, 731, 735, 739, 741, 745, 748, 751, 752, 753, 759, 760, 763, 765, 769, 770, 771, 772, 774, 778, 781, 783, 786, 787, 788, 790, 794, 795, 796, 800, 805, 806, 809, 811, 815, 817, 818, 819, 821, 822, 823, 825, 826, 828, 830, 833, 842, 843, 845, 847, 852, 855, 856, 860, 864, 866, 867, 868, 869, 871, 875, 880, 882, 883, 884, 888, 893, 894, 896, 898, 899, 902, 903, 904, 906, 908, 910, 911, 912, 913, 915, 916, 917, 919, 920, 925, 927, 930, 931, 932, 936, 937, 941, 945, 958, 964, 968, 972, 974, 975, 977, 978, 979, 980, 981, 985, 987, 989, 994, 996, 998, 999, 1000, 1003, 1007, 1011, 1012, 1016, 1022, 1023], NumPruned=52224]
230316 parameters will be pruned
-------------

2023-05-31 16:19:53.154 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.40.conv (Conv2d(615, 512, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[4, 5, 7, 9, 12, 14, 15, 17, 18, 22, 24, 30, 31, 33, 35, 37, 40, 41, 42, 47, 48, 51, 55, 57, 62, 65, 66, 68, 71, 72, 73, 74, 81, 82, 83, 84, 88, 90, 91, 92, 94, 99, 103, 106, 108, 112, 113, 118, 121, 122, 123, 126, 129, 133, 135, 138, 139, 141, 143, 144, 146, 147, 152, 154, 155, 156, 157, 159, 162, 163, 164, 166, 169, 177, 182, 183, 187, 190, 193, 198, 202, 203, 204, 210, 217, 221, 223, 224, 225, 227, 228, 233, 234, 237, 238, 244, 245, 248, 249, 254, 255, 256, 260, 261, 264, 265, 266, 271, 272, 275, 278, 280, 283, 285, 287, 288, 291, 292, 293, 295, 296, 299, 302, 308, 309, 311, 312, 313, 315, 319, 322, 325, 328, 329, 335, 339, 340, 345, 347, 348, 350, 351, 353, 354, 355, 359, 366, 369, 372, 373, 374, 377, 378, 380, 381, 383, 387, 390, 392, 393, 399, 400, 411, 415, 416, 417, 421, 422, 423, 425, 427, 431, 432, 433, 434, 437, 440, 446, 447, 449, 450, 451, 458, 460, 462, 465, 471, 473, 474, 475, 476, 477, 482, 484, 485, 490, 493, 495, 502, 503, 505, 506, 508, 509], NumPruned=125460]
[ <DEP: prune_conv => prune_batchnorm on model.40.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[4, 5, 7, 9, 12, 14, 15, 17, 18, 22, 24, 30, 31, 33, 35, 37, 40, 41, 42, 47, 48, 51, 55, 57, 62, 65, 66, 68, 71, 72, 73, 74, 81, 82, 83, 84, 88, 90, 91, 92, 94, 99, 103, 106, 108, 112, 113, 118, 121, 122, 123, 126, 129, 133, 135, 138, 139, 141, 143, 144, 146, 147, 152, 154, 155, 156, 157, 159, 162, 163, 164, 166, 169, 177, 182, 183, 187, 190, 193, 198, 202, 203, 204, 210, 217, 221, 223, 224, 225, 227, 228, 233, 234, 237, 238, 244, 245, 248, 249, 254, 255, 256, 260, 261, 264, 265, 266, 271, 272, 275, 278, 280, 283, 285, 287, 288, 291, 292, 293, 295, 296, 299, 302, 308, 309, 311, 312, 313, 315, 319, 322, 325, 328, 329, 335, 339, 340, 345, 347, 348, 350, 351, 353, 354, 355, 359, 366, 369, 372, 373, 374, 377, 378, 380, 381, 383, 387, 390, 392, 393, 399, 400, 411, 415, 416, 417, 421, 422, 423, 425, 427, 431, 432, 433, 434, 437, 440, 446, 447, 449, 450, 451, 458, 460, 462, 465, 471, 473, 474, 475, 476, 477, 482, 484, 485, 490, 493, 495, 502, 503, 505, 506, 508, 509], NumPruned=408]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[4, 5, 7, 9, 12, 14, 15, 17, 18, 22, 24, 30, 31, 33, 35, 37, 40, 41, 42, 47, 48, 51, 55, 57, 62, 65, 66, 68, 71, 72, 73, 74, 81, 82, 83, 84, 88, 90, 91, 92, 94, 99, 103, 106, 108, 112, 113, 118, 121, 122, 123, 126, 129, 133, 135, 138, 139, 141, 143, 144, 146, 147, 152, 154, 155, 156, 157, 159, 162, 163, 164, 166, 169, 177, 182, 183, 187, 190, 193, 198, 202, 203, 204, 210, 217, 221, 223, 224, 225, 227, 228, 233, 234, 237, 238, 244, 245, 248, 249, 254, 255, 256, 260, 261, 264, 265, 266, 271, 272, 275, 278, 280, 283, 285, 287, 288, 291, 292, 293, 295, 296, 299, 302, 308, 309, 311, 312, 313, 315, 319, 322, 325, 328, 329, 335, 339, 340, 345, 347, 348, 350, 351, 353, 354, 355, 359, 366, 369, 372, 373, 374, 377, 378, 380, 381, 383, 387, 390, 392, 393, 399, 400, 411, 415, 416, 417, 421, 422, 423, 425, 427, 431, 432, 433, 434, 437, 440, 446, 447, 449, 450, 451, 458, 460, 462, 465, 471, 473, 474, 475, 476, 477, 482, 484, 485, 490, 493, 495, 502, 503, 505, 506, 508, 509], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.41.conv (Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[4, 5, 7, 9, 12, 14, 15, 17, 18, 22, 24, 30, 31, 33, 35, 37, 40, 41, 42, 47, 48, 51, 55, 57, 62, 65, 66, 68, 71, 72, 73, 74, 81, 82, 83, 84, 88, 90, 91, 92, 94, 99, 103, 106, 108, 112, 113, 118, 121, 122, 123, 126, 129, 133, 135, 138, 139, 141, 143, 144, 146, 147, 152, 154, 155, 156, 157, 159, 162, 163, 164, 166, 169, 177, 182, 183, 187, 190, 193, 198, 202, 203, 204, 210, 217, 221, 223, 224, 225, 227, 228, 233, 234, 237, 238, 244, 245, 248, 249, 254, 255, 256, 260, 261, 264, 265, 266, 271, 272, 275, 278, 280, 283, 285, 287, 288, 291, 292, 293, 295, 296, 299, 302, 308, 309, 311, 312, 313, 315, 319, 322, 325, 328, 329, 335, 339, 340, 345, 347, 348, 350, 351, 353, 354, 355, 359, 366, 369, 372, 373, 374, 377, 378, 380, 381, 383, 387, 390, 392, 393, 399, 400, 411, 415, 416, 417, 421, 422, 423, 425, 427, 431, 432, 433, 434, 437, 440, 446, 447, 449, 450, 451, 458, 460, 462, 465, 471, 473, 474, 475, 476, 477, 482, 484, 485, 490, 493, 495, 502, 503, 505, 506, 508, 509], NumPruned=940032]
1065900 parameters will be pruned
-------------

2023-05-31 16:19:53.166 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.41.conv (Conv2d(308, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 4, 7, 8, 9, 12, 15, 16, 17, 22, 23, 25, 28, 29, 33, 34, 35, 36, 38, 40, 41, 45, 46, 50, 54, 55, 57, 60, 62, 64, 65, 68, 73, 76, 77, 82, 90, 94, 96, 100, 102, 104, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 122, 131, 134, 136, 137, 141, 145, 150, 153, 155, 157, 159, 161, 163, 164, 165, 168, 170, 174, 176, 178, 181, 185, 188, 193, 197, 201, 202, 204, 205, 208, 209, 210, 213, 216, 225, 226, 228, 229, 231, 232, 234, 240, 241, 242, 243, 245, 247, 248, 250, 251, 253, 256, 258, 260, 262, 264, 266, 267, 271, 274, 277, 278, 280, 281, 282, 283, 287, 289, 290, 293, 295, 296, 298, 303, 305, 318, 322, 327, 331, 332, 334, 335, 340, 343, 344, 345, 350, 356, 359, 361, 364, 365, 369, 370, 372, 373, 374, 384, 393, 396, 397, 399, 405, 406, 407, 412, 413, 417, 418, 420, 424, 425, 426, 429, 430, 433, 434, 435, 439, 443, 447, 449, 450, 454, 455, 460, 463, 464, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 487, 490, 494, 496, 499, 502, 507, 509, 510, 511], NumPruned=565488]
[ <DEP: prune_conv => prune_batchnorm on model.41.bn (BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 4, 7, 8, 9, 12, 15, 16, 17, 22, 23, 25, 28, 29, 33, 34, 35, 36, 38, 40, 41, 45, 46, 50, 54, 55, 57, 60, 62, 64, 65, 68, 73, 76, 77, 82, 90, 94, 96, 100, 102, 104, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 122, 131, 134, 136, 137, 141, 145, 150, 153, 155, 157, 159, 161, 163, 164, 165, 168, 170, 174, 176, 178, 181, 185, 188, 193, 197, 201, 202, 204, 205, 208, 209, 210, 213, 216, 225, 226, 228, 229, 231, 232, 234, 240, 241, 242, 243, 245, 247, 248, 250, 251, 253, 256, 258, 260, 262, 264, 266, 267, 271, 274, 277, 278, 280, 281, 282, 283, 287, 289, 290, 293, 295, 296, 298, 303, 305, 318, 322, 327, 331, 332, 334, 335, 340, 343, 344, 345, 350, 356, 359, 361, 364, 365, 369, 370, 372, 373, 374, 384, 393, 396, 397, 399, 405, 406, 407, 412, 413, 417, 418, 420, 424, 425, 426, 429, 430, 433, 434, 435, 439, 443, 447, 449, 450, 454, 455, 460, 463, 464, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 487, 490, 494, 496, 499, 502, 507, 509, 510, 511], NumPruned=408]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 4, 7, 8, 9, 12, 15, 16, 17, 22, 23, 25, 28, 29, 33, 34, 35, 36, 38, 40, 41, 45, 46, 50, 54, 55, 57, 60, 62, 64, 65, 68, 73, 76, 77, 82, 90, 94, 96, 100, 102, 104, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 122, 131, 134, 136, 137, 141, 145, 150, 153, 155, 157, 159, 161, 163, 164, 165, 168, 170, 174, 176, 178, 181, 185, 188, 193, 197, 201, 202, 204, 205, 208, 209, 210, 213, 216, 225, 226, 228, 229, 231, 232, 234, 240, 241, 242, 243, 245, 247, 248, 250, 251, 253, 256, 258, 260, 262, 264, 266, 267, 271, 274, 277, 278, 280, 281, 282, 283, 287, 289, 290, 293, 295, 296, 298, 303, 305, 318, 322, 327, 331, 332, 334, 335, 340, 343, 344, 345, 350, 356, 359, 361, 364, 365, 369, 370, 372, 373, 374, 384, 393, 396, 397, 399, 405, 406, 407, 412, 413, 417, 418, 420, 424, 425, 426, 429, 430, 433, 434, 435, 439, 443, 447, 449, 450, 454, 455, 460, 463, 464, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 487, 490, 494, 496, 499, 502, 507, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 512, 820])>, Index=[1, 4, 7, 8, 9, 12, 15, 16, 17, 22, 23, 25, 28, 29, 33, 34, 35, 36, 38, 40, 41, 45, 46, 50, 54, 55, 57, 60, 62, 64, 65, 68, 73, 76, 77, 82, 90, 94, 96, 100, 102, 104, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 122, 131, 134, 136, 137, 141, 145, 150, 153, 155, 157, 159, 161, 163, 164, 165, 168, 170, 174, 176, 178, 181, 185, 188, 193, 197, 201, 202, 204, 205, 208, 209, 210, 213, 216, 225, 226, 228, 229, 231, 232, 234, 240, 241, 242, 243, 245, 247, 248, 250, 251, 253, 256, 258, 260, 262, 264, 266, 267, 271, 274, 277, 278, 280, 281, 282, 283, 287, 289, 290, 293, 295, 296, 298, 303, 305, 318, 322, 327, 331, 332, 334, 335, 340, 343, 344, 345, 350, 356, 359, 361, 364, 365, 369, 370, 372, 373, 374, 384, 393, 396, 397, 399, 405, 406, 407, 412, 413, 417, 418, 420, 424, 425, 426, 429, 430, 433, 434, 435, 439, 443, 447, 449, 450, 454, 455, 460, 463, 464, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 487, 490, 494, 496, 499, 502, 507, 509, 510, 511], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.44.conv (Conv2d(820, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 7, 8, 9, 12, 15, 16, 17, 22, 23, 25, 28, 29, 33, 34, 35, 36, 38, 40, 41, 45, 46, 50, 54, 55, 57, 60, 62, 64, 65, 68, 73, 76, 77, 82, 90, 94, 96, 100, 102, 104, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 122, 131, 134, 136, 137, 141, 145, 150, 153, 155, 157, 159, 161, 163, 164, 165, 168, 170, 174, 176, 178, 181, 185, 188, 193, 197, 201, 202, 204, 205, 208, 209, 210, 213, 216, 225, 226, 228, 229, 231, 232, 234, 240, 241, 242, 243, 245, 247, 248, 250, 251, 253, 256, 258, 260, 262, 264, 266, 267, 271, 274, 277, 278, 280, 281, 282, 283, 287, 289, 290, 293, 295, 296, 298, 303, 305, 318, 322, 327, 331, 332, 334, 335, 340, 343, 344, 345, 350, 356, 359, 361, 364, 365, 369, 370, 372, 373, 374, 384, 393, 396, 397, 399, 405, 406, 407, 412, 413, 417, 418, 420, 424, 425, 426, 429, 430, 433, 434, 435, 439, 443, 447, 449, 450, 454, 455, 460, 463, 464, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 487, 490, 494, 496, 499, 502, 507, 509, 510, 511], NumPruned=52224]
[ <DEP: _prune_concat => prune_related_conv on model.43.conv (Conv2d(820, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 4, 7, 8, 9, 12, 15, 16, 17, 22, 23, 25, 28, 29, 33, 34, 35, 36, 38, 40, 41, 45, 46, 50, 54, 55, 57, 60, 62, 64, 65, 68, 73, 76, 77, 82, 90, 94, 96, 100, 102, 104, 106, 107, 110, 111, 113, 114, 116, 118, 119, 121, 122, 131, 134, 136, 137, 141, 145, 150, 153, 155, 157, 159, 161, 163, 164, 165, 168, 170, 174, 176, 178, 181, 185, 188, 193, 197, 201, 202, 204, 205, 208, 209, 210, 213, 216, 225, 226, 228, 229, 231, 232, 234, 240, 241, 242, 243, 245, 247, 248, 250, 251, 253, 256, 258, 260, 262, 264, 266, 267, 271, 274, 277, 278, 280, 281, 282, 283, 287, 289, 290, 293, 295, 296, 298, 303, 305, 318, 322, 327, 331, 332, 334, 335, 340, 343, 344, 345, 350, 356, 359, 361, 364, 365, 369, 370, 372, 373, 374, 384, 393, 396, 397, 399, 405, 406, 407, 412, 413, 417, 418, 420, 424, 425, 426, 429, 430, 433, 434, 435, 439, 443, 447, 449, 450, 454, 455, 460, 463, 464, 466, 467, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 483, 487, 490, 494, 496, 499, 502, 507, 509, 510, 511], NumPruned=52224]
670344 parameters will be pruned
-------------

2023-05-31 16:19:53.175 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.43.conv (Conv2d(616, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 5, 9, 10, 15, 16, 18, 19, 21, 24, 25, 26, 30, 36, 39, 41, 42, 44, 45, 46, 57, 62, 64, 65, 68, 74, 75, 77, 78, 80, 87, 88, 91, 97, 100, 101, 102, 103, 104, 110, 111, 117, 118, 120, 121, 123, 126, 127, 128, 129, 133, 141, 142, 143, 144, 148, 151, 152, 153, 158, 160, 162, 163, 167, 170, 171, 174, 178, 179, 180, 184, 185, 189, 193, 196, 197, 198, 199, 200, 201, 207, 209, 211, 214, 217, 219, 221, 222, 223, 226, 230, 231, 233, 239, 243, 244, 249, 251, 252, 253, 254, 255], NumPruned=62832]
[ <DEP: prune_conv => prune_batchnorm on model.43.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 5, 9, 10, 15, 16, 18, 19, 21, 24, 25, 26, 30, 36, 39, 41, 42, 44, 45, 46, 57, 62, 64, 65, 68, 74, 75, 77, 78, 80, 87, 88, 91, 97, 100, 101, 102, 103, 104, 110, 111, 117, 118, 120, 121, 123, 126, 127, 128, 129, 133, 141, 142, 143, 144, 148, 151, 152, 153, 158, 160, 162, 163, 167, 170, 171, 174, 178, 179, 180, 184, 185, 189, 193, 196, 197, 198, 199, 200, 201, 207, 209, 211, 214, 217, 219, 221, 222, 223, 226, 230, 231, 233, 239, 243, 244, 249, 251, 252, 253, 254, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 5, 9, 10, 15, 16, 18, 19, 21, 24, 25, 26, 30, 36, 39, 41, 42, 44, 45, 46, 57, 62, 64, 65, 68, 74, 75, 77, 78, 80, 87, 88, 91, 97, 100, 101, 102, 103, 104, 110, 111, 117, 118, 120, 121, 123, 126, 127, 128, 129, 133, 141, 142, 143, 144, 148, 151, 152, 153, 158, 160, 162, 163, 167, 170, 171, 174, 178, 179, 180, 184, 185, 189, 193, 196, 197, 198, 199, 200, 201, 207, 209, 211, 214, 217, 219, 221, 222, 223, 226, 230, 231, 233, 239, 243, 244, 249, 251, 252, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 1024])>, Index=[768, 773, 777, 778, 783, 784, 786, 787, 789, 792, 793, 794, 798, 804, 807, 809, 810, 812, 813, 814, 825, 830, 832, 833, 836, 842, 843, 845, 846, 848, 855, 856, 859, 865, 868, 869, 870, 871, 872, 878, 879, 885, 886, 888, 889, 891, 894, 895, 896, 897, 901, 909, 910, 911, 912, 916, 919, 920, 921, 926, 928, 930, 931, 935, 938, 939, 942, 946, 947, 948, 952, 953, 957, 961, 964, 965, 966, 967, 968, 969, 975, 977, 979, 982, 985, 987, 989, 990, 991, 994, 998, 999, 1001, 1007, 1011, 1012, 1017, 1019, 1020, 1021, 1022, 1023], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[768, 773, 777, 778, 783, 784, 786, 787, 789, 792, 793, 794, 798, 804, 807, 809, 810, 812, 813, 814, 825, 830, 832, 833, 836, 842, 843, 845, 846, 848, 855, 856, 859, 865, 868, 869, 870, 871, 872, 878, 879, 885, 886, 888, 889, 891, 894, 895, 896, 897, 901, 909, 910, 911, 912, 916, 919, 920, 921, 926, 928, 930, 931, 935, 938, 939, 942, 946, 947, 948, 952, 953, 957, 961, 964, 965, 966, 967, 968, 969, 975, 977, 979, 982, 985, 987, 989, 990, 991, 994, 998, 999, 1001, 1007, 1011, 1012, 1017, 1019, 1020, 1021, 1022, 1023], NumPruned=104448]
167484 parameters will be pruned
-------------

2023-05-31 16:19:53.179 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.44.conv (Conv2d(616, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 7, 8, 15, 17, 21, 24, 25, 28, 31, 32, 34, 38, 40, 41, 46, 47, 54, 55, 56, 59, 60, 62, 63, 64, 67, 68, 74, 76, 78, 80, 81, 84, 85, 86, 87, 91, 93, 96, 103, 104, 108, 109, 111, 113, 114, 115, 117, 121, 122, 125, 126, 127, 129, 133, 134, 136, 138, 139, 141, 142, 144, 146, 148, 149, 150, 153, 160, 165, 166, 168, 170, 175, 177, 179, 185, 190, 194, 199, 200, 203, 206, 207, 209, 210, 211, 217, 218, 220, 223, 225, 227, 228, 239, 240, 241, 245, 247, 249, 250, 252], NumPruned=62832]
[ <DEP: prune_conv => prune_batchnorm on model.44.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 7, 8, 15, 17, 21, 24, 25, 28, 31, 32, 34, 38, 40, 41, 46, 47, 54, 55, 56, 59, 60, 62, 63, 64, 67, 68, 74, 76, 78, 80, 81, 84, 85, 86, 87, 91, 93, 96, 103, 104, 108, 109, 111, 113, 114, 115, 117, 121, 122, 125, 126, 127, 129, 133, 134, 136, 138, 139, 141, 142, 144, 146, 148, 149, 150, 153, 160, 165, 166, 168, 170, 175, 177, 179, 185, 190, 194, 199, 200, 203, 206, 207, 209, 210, 211, 217, 218, 220, 223, 225, 227, 228, 239, 240, 241, 245, 247, 249, 250, 252], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 7, 8, 15, 17, 21, 24, 25, 28, 31, 32, 34, 38, 40, 41, 46, 47, 54, 55, 56, 59, 60, 62, 63, 64, 67, 68, 74, 76, 78, 80, 81, 84, 85, 86, 87, 91, 93, 96, 103, 104, 108, 109, 111, 113, 114, 115, 117, 121, 122, 125, 126, 127, 129, 133, 134, 136, 138, 139, 141, 142, 144, 146, 148, 149, 150, 153, 160, 165, 166, 168, 170, 175, 177, 179, 185, 190, 194, 199, 200, 203, 206, 207, 209, 210, 211, 217, 218, 220, 223, 225, 227, 228, 239, 240, 241, 245, 247, 249, 250, 252], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.45.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 3, 7, 8, 15, 17, 21, 24, 25, 28, 31, 32, 34, 38, 40, 41, 46, 47, 54, 55, 56, 59, 60, 62, 63, 64, 67, 68, 74, 76, 78, 80, 81, 84, 85, 86, 87, 91, 93, 96, 103, 104, 108, 109, 111, 113, 114, 115, 117, 121, 122, 125, 126, 127, 129, 133, 134, 136, 138, 139, 141, 142, 144, 146, 148, 149, 150, 153, 160, 165, 166, 168, 170, 175, 177, 179, 185, 190, 194, 199, 200, 203, 206, 207, 209, 210, 211, 217, 218, 220, 223, 225, 227, 228, 239, 240, 241, 245, 247, 249, 250, 252], NumPruned=235008]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 768, 922])>, Index=[512, 515, 519, 520, 527, 529, 533, 536, 537, 540, 543, 544, 546, 550, 552, 553, 558, 559, 566, 567, 568, 571, 572, 574, 575, 576, 579, 580, 586, 588, 590, 592, 593, 596, 597, 598, 599, 603, 605, 608, 615, 616, 620, 621, 623, 625, 626, 627, 629, 633, 634, 637, 638, 639, 641, 645, 646, 648, 650, 651, 653, 654, 656, 658, 660, 661, 662, 665, 672, 677, 678, 680, 682, 687, 689, 691, 697, 702, 706, 711, 712, 715, 718, 719, 721, 722, 723, 729, 730, 732, 735, 737, 739, 740, 751, 752, 753, 757, 759, 761, 762, 764], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(922, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[512, 515, 519, 520, 527, 529, 533, 536, 537, 540, 543, 544, 546, 550, 552, 553, 558, 559, 566, 567, 568, 571, 572, 574, 575, 576, 579, 580, 586, 588, 590, 592, 593, 596, 597, 598, 599, 603, 605, 608, 615, 616, 620, 621, 623, 625, 626, 627, 629, 633, 634, 637, 638, 639, 641, 645, 646, 648, 650, 651, 653, 654, 656, 658, 660, 661, 662, 665, 672, 677, 678, 680, 682, 687, 689, 691, 697, 702, 706, 711, 712, 715, 718, 719, 721, 722, 723, 729, 730, 732, 735, 737, 739, 740, 751, 752, 753, 757, 759, 761, 762, 764], NumPruned=104448]
402492 parameters will be pruned
-------------

2023-05-31 16:19:53.183 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.45.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 6, 8, 9, 12, 15, 16, 17, 21, 22, 23, 26, 27, 28, 30, 34, 35, 37, 38, 42, 43, 44, 50, 53, 59, 61, 68, 73, 75, 77, 78, 80, 84, 86, 87, 89, 91, 93, 102, 106, 108, 112, 116, 117, 119, 123, 125, 130, 132, 134, 135, 137, 139, 141, 143, 144, 146, 147, 148, 149, 151, 152, 154, 155, 160, 161, 166, 167, 168, 177, 179, 180, 182, 183, 186, 187, 188, 191, 195, 200, 204, 205, 206, 209, 211, 212, 216, 218, 220, 222, 223, 228, 229, 230, 234, 238, 245, 249, 252, 255], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.45.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 3, 4, 6, 8, 9, 12, 15, 16, 17, 21, 22, 23, 26, 27, 28, 30, 34, 35, 37, 38, 42, 43, 44, 50, 53, 59, 61, 68, 73, 75, 77, 78, 80, 84, 86, 87, 89, 91, 93, 102, 106, 108, 112, 116, 117, 119, 123, 125, 130, 132, 134, 135, 137, 139, 141, 143, 144, 146, 147, 148, 149, 151, 152, 154, 155, 160, 161, 166, 167, 168, 177, 179, 180, 182, 183, 186, 187, 188, 191, 195, 200, 204, 205, 206, 209, 211, 212, 216, 218, 220, 222, 223, 228, 229, 230, 234, 238, 245, 249, 252, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 3, 4, 6, 8, 9, 12, 15, 16, 17, 21, 22, 23, 26, 27, 28, 30, 34, 35, 37, 38, 42, 43, 44, 50, 53, 59, 61, 68, 73, 75, 77, 78, 80, 84, 86, 87, 89, 91, 93, 102, 106, 108, 112, 116, 117, 119, 123, 125, 130, 132, 134, 135, 137, 139, 141, 143, 144, 146, 147, 148, 149, 151, 152, 154, 155, 160, 161, 166, 167, 168, 177, 179, 180, 182, 183, 186, 187, 188, 191, 195, 200, 204, 205, 206, 209, 211, 212, 216, 218, 220, 222, 223, 228, 229, 230, 234, 238, 245, 249, 252, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.46.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 3, 4, 6, 8, 9, 12, 15, 16, 17, 21, 22, 23, 26, 27, 28, 30, 34, 35, 37, 38, 42, 43, 44, 50, 53, 59, 61, 68, 73, 75, 77, 78, 80, 84, 86, 87, 89, 91, 93, 102, 106, 108, 112, 116, 117, 119, 123, 125, 130, 132, 134, 135, 137, 139, 141, 143, 144, 146, 147, 148, 149, 151, 152, 154, 155, 160, 161, 166, 167, 168, 177, 179, 180, 182, 183, 186, 187, 188, 191, 195, 200, 204, 205, 206, 209, 211, 212, 216, 218, 220, 222, 223, 228, 229, 230, 234, 238, 245, 249, 252, 255], NumPruned=235008]
376584 parameters will be pruned
-------------

2023-05-31 16:19:53.186 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.46.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 8, 14, 15, 17, 21, 24, 27, 29, 31, 36, 37, 40, 44, 47, 48, 50, 53, 54, 57, 58, 60, 61, 63, 64, 67, 70, 74, 76, 79, 81, 84, 86, 88, 90, 91, 92, 94, 96, 104, 108, 110, 111, 112, 114, 116, 117, 118, 120, 122, 125, 126, 130, 132, 138, 140, 141, 143, 148, 150, 155, 158, 160, 161, 162, 165, 166, 169, 171, 172, 173, 174, 175, 176, 177, 181, 182, 184, 186, 190, 192, 194, 196, 197, 198, 199, 208, 209, 213, 216, 218, 219, 220, 221, 229, 233, 238, 239, 240, 243, 247, 250], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.46.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 8, 14, 15, 17, 21, 24, 27, 29, 31, 36, 37, 40, 44, 47, 48, 50, 53, 54, 57, 58, 60, 61, 63, 64, 67, 70, 74, 76, 79, 81, 84, 86, 88, 90, 91, 92, 94, 96, 104, 108, 110, 111, 112, 114, 116, 117, 118, 120, 122, 125, 126, 130, 132, 138, 140, 141, 143, 148, 150, 155, 158, 160, 161, 162, 165, 166, 169, 171, 172, 173, 174, 175, 176, 177, 181, 182, 184, 186, 190, 192, 194, 196, 197, 198, 199, 208, 209, 213, 216, 218, 219, 220, 221, 229, 233, 238, 239, 240, 243, 247, 250], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 8, 14, 15, 17, 21, 24, 27, 29, 31, 36, 37, 40, 44, 47, 48, 50, 53, 54, 57, 58, 60, 61, 63, 64, 67, 70, 74, 76, 79, 81, 84, 86, 88, 90, 91, 92, 94, 96, 104, 108, 110, 111, 112, 114, 116, 117, 118, 120, 122, 125, 126, 130, 132, 138, 140, 141, 143, 148, 150, 155, 158, 160, 161, 162, 165, 166, 169, 171, 172, 173, 174, 175, 176, 177, 181, 182, 184, 186, 190, 192, 194, 196, 197, 198, 199, 208, 209, 213, 216, 218, 219, 220, 221, 229, 233, 238, 239, 240, 243, 247, 250], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.47.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 8, 14, 15, 17, 21, 24, 27, 29, 31, 36, 37, 40, 44, 47, 48, 50, 53, 54, 57, 58, 60, 61, 63, 64, 67, 70, 74, 76, 79, 81, 84, 86, 88, 90, 91, 92, 94, 96, 104, 108, 110, 111, 112, 114, 116, 117, 118, 120, 122, 125, 126, 130, 132, 138, 140, 141, 143, 148, 150, 155, 158, 160, 161, 162, 165, 166, 169, 171, 172, 173, 174, 175, 176, 177, 181, 182, 184, 186, 190, 192, 194, 196, 197, 198, 199, 208, 209, 213, 216, 218, 219, 220, 221, 229, 233, 238, 239, 240, 243, 247, 250], NumPruned=235008]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 512, 666, 820])>, Index=[258, 264, 270, 271, 273, 277, 280, 283, 285, 287, 292, 293, 296, 300, 303, 304, 306, 309, 310, 313, 314, 316, 317, 319, 320, 323, 326, 330, 332, 335, 337, 340, 342, 344, 346, 347, 348, 350, 352, 360, 364, 366, 367, 368, 370, 372, 373, 374, 376, 378, 381, 382, 386, 388, 394, 396, 397, 399, 404, 406, 411, 414, 416, 417, 418, 421, 422, 425, 427, 428, 429, 430, 431, 432, 433, 437, 438, 440, 442, 446, 448, 450, 452, 453, 454, 455, 464, 465, 469, 472, 474, 475, 476, 477, 485, 489, 494, 495, 496, 499, 503, 506], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(820, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[258, 264, 270, 271, 273, 277, 280, 283, 285, 287, 292, 293, 296, 300, 303, 304, 306, 309, 310, 313, 314, 316, 317, 319, 320, 323, 326, 330, 332, 335, 337, 340, 342, 344, 346, 347, 348, 350, 352, 360, 364, 366, 367, 368, 370, 372, 373, 374, 376, 378, 381, 382, 386, 388, 394, 396, 397, 399, 404, 406, 411, 414, 416, 417, 418, 421, 422, 425, 427, 428, 429, 430, 431, 432, 433, 437, 438, 440, 442, 446, 448, 450, 452, 453, 454, 455, 464, 465, 469, 472, 474, 475, 476, 477, 485, 489, 494, 495, 496, 499, 503, 506], NumPruned=104448]
481032 parameters will be pruned
-------------

2023-05-31 16:19:53.190 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.47.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 24, 26, 29, 34, 35, 36, 37, 38, 42, 43, 45, 49, 58, 61, 65, 67, 69, 76, 78, 81, 82, 83, 84, 85, 89, 90, 95, 99, 101, 106, 112, 113, 115, 118, 122, 125, 127, 132, 137, 139, 140, 141, 142, 144, 147, 148, 149, 151, 153, 156, 157, 158, 160, 162, 165, 166, 169, 172, 175, 177, 183, 184, 185, 189, 190, 192, 194, 196, 199, 204, 206, 210, 214, 220, 222, 224, 225, 227, 233, 234, 235, 236, 244, 247, 250, 251, 255], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.47.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 24, 26, 29, 34, 35, 36, 37, 38, 42, 43, 45, 49, 58, 61, 65, 67, 69, 76, 78, 81, 82, 83, 84, 85, 89, 90, 95, 99, 101, 106, 112, 113, 115, 118, 122, 125, 127, 132, 137, 139, 140, 141, 142, 144, 147, 148, 149, 151, 153, 156, 157, 158, 160, 162, 165, 166, 169, 172, 175, 177, 183, 184, 185, 189, 190, 192, 194, 196, 199, 204, 206, 210, 214, 220, 222, 224, 225, 227, 233, 234, 235, 236, 244, 247, 250, 251, 255], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 24, 26, 29, 34, 35, 36, 37, 38, 42, 43, 45, 49, 58, 61, 65, 67, 69, 76, 78, 81, 82, 83, 84, 85, 89, 90, 95, 99, 101, 106, 112, 113, 115, 118, 122, 125, 127, 132, 137, 139, 140, 141, 142, 144, 147, 148, 149, 151, 153, 156, 157, 158, 160, 162, 165, 166, 169, 172, 175, 177, 183, 184, 185, 189, 190, 192, 194, 196, 199, 204, 206, 210, 214, 220, 222, 224, 225, 227, 233, 234, 235, 236, 244, 247, 250, 251, 255], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.48.conv (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 24, 26, 29, 34, 35, 36, 37, 38, 42, 43, 45, 49, 58, 61, 65, 67, 69, 76, 78, 81, 82, 83, 84, 85, 89, 90, 95, 99, 101, 106, 112, 113, 115, 118, 122, 125, 127, 132, 137, 139, 140, 141, 142, 144, 147, 148, 149, 151, 153, 156, 157, 158, 160, 162, 165, 166, 169, 172, 175, 177, 183, 184, 185, 189, 190, 192, 194, 196, 199, 204, 206, 210, 214, 220, 222, 224, 225, 227, 233, 234, 235, 236, 244, 247, 250, 251, 255], NumPruned=235008]
376584 parameters will be pruned
-------------

2023-05-31 16:19:53.193 | INFO     | __main__:layer_pruning:70 - 
-------------
[ <DEP: prune_conv => prune_conv on model.48.conv (Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[3, 5, 7, 8, 9, 10, 14, 17, 18, 19, 22, 28, 31, 38, 39, 42, 43, 46, 47, 54, 57, 59, 60, 61, 64, 65, 69, 75, 76, 78, 79, 81, 82, 85, 88, 89, 90, 91, 98, 102, 104, 105, 106, 108, 111, 112, 115, 116, 118, 120, 126, 128, 129, 131, 133, 134, 135, 140, 145, 147, 148, 149, 151, 152, 155, 156, 158, 160, 161, 164, 166, 168, 172, 173, 174, 180, 181, 185, 186, 190, 193, 195, 198, 203, 204, 206, 208, 210, 218, 219, 222, 225, 226, 231, 234, 238, 239, 244, 246, 249, 250, 254], NumPruned=141372]
[ <DEP: prune_conv => prune_batchnorm on model.48.bn (BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[3, 5, 7, 8, 9, 10, 14, 17, 18, 19, 22, 28, 31, 38, 39, 42, 43, 46, 47, 54, 57, 59, 60, 61, 64, 65, 69, 75, 76, 78, 79, 81, 82, 85, 88, 89, 90, 91, 98, 102, 104, 105, 106, 108, 111, 112, 115, 116, 118, 120, 126, 128, 129, 131, 133, 134, 135, 140, 145, 147, 148, 149, 151, 152, 155, 156, 158, 160, 161, 164, 166, 168, 172, 173, 174, 180, 181, 185, 186, 190, 193, 195, 198, 203, 204, 206, 208, 210, 218, 219, 222, 225, 226, 231, 234, 238, 239, 244, 246, 249, 250, 254], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[3, 5, 7, 8, 9, 10, 14, 17, 18, 19, 22, 28, 31, 38, 39, 42, 43, 46, 47, 54, 57, 59, 60, 61, 64, 65, 69, 75, 76, 78, 79, 81, 82, 85, 88, 89, 90, 91, 98, 102, 104, 105, 106, 108, 111, 112, 115, 116, 118, 120, 126, 128, 129, 131, 133, 134, 135, 140, 145, 147, 148, 149, 151, 152, 155, 156, 158, 160, 161, 164, 166, 168, 172, 173, 174, 180, 181, 185, 186, 190, 193, 195, 198, 203, 204, 206, 208, 210, 218, 219, 222, 225, 226, 231, 234, 238, 239, 244, 246, 249, 250, 254], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 256, 410, 564, 718])>, Index=[3, 5, 7, 8, 9, 10, 14, 17, 18, 19, 22, 28, 31, 38, 39, 42, 43, 46, 47, 54, 57, 59, 60, 61, 64, 65, 69, 75, 76, 78, 79, 81, 82, 85, 88, 89, 90, 91, 98, 102, 104, 105, 106, 108, 111, 112, 115, 116, 118, 120, 126, 128, 129, 131, 133, 134, 135, 140, 145, 147, 148, 149, 151, 152, 155, 156, 158, 160, 161, 164, 166, 168, 172, 173, 174, 180, 181, 185, 186, 190, 193, 195, 198, 203, 204, 206, 208, 210, 218, 219, 222, 225, 226, 231, 234, 238, 239, 244, 246, 249, 250, 254], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.50.conv (Conv2d(718, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[3, 5, 7, 8, 9, 10, 14, 17, 18, 19, 22, 28, 31, 38, 39, 42, 43, 46, 47, 54, 57, 59, 60, 61, 64, 65, 69, 75, 76, 78, 79, 81, 82, 85, 88, 89, 90, 91, 98, 102, 104, 105, 106, 108, 111, 112, 115, 116, 118, 120, 126, 128, 129, 131, 133, 134, 135, 140, 145, 147, 148, 149, 151, 152, 155, 156, 158, 160, 161, 164, 166, 168, 172, 173, 174, 180, 181, 185, 186, 190, 193, 195, 198, 203, 204, 206, 208, 210, 218, 219, 222, 225, 226, 231, 234, 238, 239, 244, 246, 249, 250, 254], NumPruned=104448]
246024 parameters will be pruned
-------------

2023-05-31 16:19:53.197 | INFO     | __main__:layer_pruning:76 -   Params: 37196556 => 28791661

2023-05-31 16:19:53.309 | INFO     | __main__:layer_pruning:90 - 剪枝完成

2023-05-31 16:58:34.795 | ERROR    | __main__:<module>:98 - An error has been caught in function '<module>', process 'MainProcess' (12440), thread 'MainThread' (7812):
Traceback (most recent call last):

> File "E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\tools\prunmodel.py", line 98, in <module>
    layer_pruning(r'E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\runs\train\v7_results\exp_yuan_B8_Epoch200\weights\best.pt')
    └ <function layer_pruning at 0x0000000011626940>

  File "E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\tools\prunmodel.py", line 43, in layer_pruning
    device = select_device('cuda')
             └ <function select_device at 0x000000000DEAD160>

  File "E:\chengxu\paper2-MinePersonnel-Code\yolov7-main\utils\torch_utils.py", line 71, in select_device
    assert torch.cuda.is_available(), f'CUDA unavailable, invalid device {device} requested'  # check availability
           │     │    └ <function is_available at 0x0000000005958B80>
           │     └ <module 'torch.cuda' from 'D:\\annconda\\lib\\site-packages\\torch\\cuda\\__init__.py'>
           └ <module 'torch' from 'D:\\annconda\\lib\\site-packages\\torch\\__init__.py'>

AssertionError: CUDA unavailable, invalid device cuda requested
2023-05-31 16:58:44.002 | INFO     | __main__:layer_pruning:63 - [Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)]
2023-05-31 16:58:44.004 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=675]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=14400]
15125 parameters will be pruned
-------------

2023-05-31 16:58:44.005 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.0.bn (BatchNorm2d(7, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4], NumPruned=10]
[ <DEP: prune_batchnorm => prune_conv on model.0.conv (Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4], NumPruned=135]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(7, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4], NumPruned=2880]
3025 parameters will be pruned
-------------

2023-05-31 16:58:44.005 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(2, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=918]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=29376]
30396 parameters will be pruned
-------------

2023-05-31 16:58:44.006 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.1.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.1.conv (Conv2d(2, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=180]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=5760]
5960 parameters will be pruned
-------------

2023-05-31 16:58:44.009 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=1377]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=58752]
60231 parameters will be pruned
-------------

2023-05-31 16:58:44.010 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.2.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.2.conv (Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=270]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(13, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=11520]
11810 parameters will be pruned
-------------

2023-05-31 16:58:44.011 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=2754]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=6528]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=6528]
16014 parameters will be pruned
-------------

2023-05-31 16:58:44.012 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.3.bn (BatchNorm2d(26, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=40]
[ <DEP: prune_batchnorm => prune_conv on model.3.conv (Conv2d(3, 26, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=540]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(26, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=1280]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(26, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=1280]
3140 parameters will be pruned
-------------

2023-05-31 16:58:44.012 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=306]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[192, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[192, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255], NumPruned=13056]
13464 parameters will be pruned
-------------

2023-05-31 16:58:44.013 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.4.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 9, 10, 11], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.4.conv (Conv2d(6, 13, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 9, 10, 11], NumPruned=60]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 9, 10, 11], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 205])>, Index=[192, 193, 194, 195, 196, 198, 199, 201, 202, 203], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(205, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[192, 193, 194, 195, 196, 198, 199, 201, 202, 203], NumPruned=2560]
2640 parameters will be pruned
-------------

2023-05-31 16:58:44.014 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=306]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=29376]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 195])>, Index=[128, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 150, 151, 152, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 185, 186, 188, 189, 190, 191], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(195, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 150, 151, 152, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 185, 186, 188, 189, 190, 191], NumPruned=13056]
42840 parameters will be pruned
-------------

2023-05-31 16:58:44.015 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.5.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=22]
[ <DEP: prune_batchnorm => prune_conv on model.5.conv (Conv2d(6, 13, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=66]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=6336]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 141, 144])>, Index=[128, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140], NumPruned=2816]
9240 parameters will be pruned
-------------

2023-05-31 16:58:44.016 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=918]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=29376]
30396 parameters will be pruned
-------------

2023-05-31 16:58:44.016 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.6.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.6.conv (Conv2d(2, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=180]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=5760]
5960 parameters will be pruned
-------------

2023-05-31 16:58:44.017 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=1377]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=29376]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 130, 133])>, Index=[64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 111, 113, 114, 115, 117, 118, 119, 121, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(133, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 111, 113, 114, 115, 117, 118, 119, 121, 124, 125, 126, 127], NumPruned=13056]
43911 parameters will be pruned
-------------

2023-05-31 16:58:44.018 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.7.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.7.conv (Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=270]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=5760]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 77, 79, 82])>, Index=[64, 65, 66, 67, 69, 70, 71, 73, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(82, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 69, 70, 71, 73, 75, 76], NumPruned=2560]
8610 parameters will be pruned
-------------

2023-05-31 16:58:44.019 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=1377]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=29376]
30855 parameters will be pruned
-------------

2023-05-31 16:58:44.020 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.8.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=22]
[ <DEP: prune_batchnorm => prune_conv on model.8.conv (Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=297]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=6336]
6655 parameters will be pruned
-------------

2023-05-31 16:58:44.020 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=918]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 67, 69, 72])>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(72, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=13056]
14076 parameters will be pruned
-------------

2023-05-31 16:58:44.021 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.9.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=22]
[ <DEP: prune_batchnorm => prune_conv on model.9.conv (Conv2d(2, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=198]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 13, 16, 18, 21])>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(21, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=2816]
3036 parameters will be pruned
-------------

2023-05-31 16:58:44.022 | INFO     | __main__:layer_pruning:84 -   Params: 37196556 => 36839172

2023-05-31 16:58:44.180 | INFO     | __main__:layer_pruning:95 - 剪枝完成

2023-05-31 17:14:14.139 | INFO     | __main__:layer_pruning:63 - [Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False), BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False), BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)]
2023-05-31 17:14:14.141 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.0.conv (Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=675]
[ <DEP: prune_conv => prune_batchnorm on model.0.bn (BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=50]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], NumPruned=14400]
15125 parameters will be pruned
-------------

2023-05-31 17:14:14.142 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.0.bn (BatchNorm2d(7, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4], NumPruned=10]
[ <DEP: prune_batchnorm => prune_conv on model.0.conv (Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4], NumPruned=135]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.1.conv (Conv2d(7, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4], NumPruned=2880]
3025 parameters will be pruned
-------------

2023-05-31 17:14:14.143 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.1.conv (Conv2d(2, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=918]
[ <DEP: prune_conv => prune_batchnorm on model.1.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=29376]
30396 parameters will be pruned
-------------

2023-05-31 17:14:14.144 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.1.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.1.conv (Conv2d(2, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=180]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.2.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 11, 12], NumPruned=5760]
5960 parameters will be pruned
-------------

2023-05-31 17:14:14.145 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.2.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=1377]
[ <DEP: prune_conv => prune_batchnorm on model.2.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61], NumPruned=58752]
60231 parameters will be pruned
-------------

2023-05-31 17:14:14.146 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.2.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.2.conv (Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=270]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.3.conv (Conv2d(13, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], NumPruned=11520]
11810 parameters will be pruned
-------------

2023-05-31 17:14:14.147 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.3.conv (Conv2d(3, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=2754]
[ <DEP: prune_conv => prune_batchnorm on model.3.bn (BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=204]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=6528]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 53, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 111, 112, 113, 114, 115, 118, 119, 121, 122, 123, 125, 126, 127], NumPruned=6528]
16014 parameters will be pruned
-------------

2023-05-31 17:14:14.148 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.3.bn (BatchNorm2d(26, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=40]
[ <DEP: prune_batchnorm => prune_conv on model.3.conv (Conv2d(3, 26, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=540]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.5.conv (Conv2d(26, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=1280]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.4.conv (Conv2d(26, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 20, 21, 23, 24], NumPruned=1280]
3140 parameters will be pruned
-------------

2023-05-31 17:14:14.149 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.4.conv (Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=306]
[ <DEP: prune_conv => prune_batchnorm on model.4.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 256])>, Index=[192, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[192, 195, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 214, 215, 216, 217, 219, 220, 221, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 253, 254, 255], NumPruned=13056]
13464 parameters will be pruned
-------------

2023-05-31 17:14:14.150 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.4.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 9, 10, 11], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.4.conv (Conv2d(6, 13, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 9, 10, 11], NumPruned=60]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 9, 10, 11], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 205])>, Index=[192, 193, 194, 195, 196, 198, 199, 201, 202, 203], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(205, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[192, 193, 194, 195, 196, 198, 199, 201, 202, 203], NumPruned=2560]
2640 parameters will be pruned
-------------

2023-05-31 17:14:14.151 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.5.conv (Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=306]
[ <DEP: prune_conv => prune_batchnorm on model.5.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 50, 51, 52, 55, 57, 58, 60, 61, 62, 63], NumPruned=29376]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 192, 195])>, Index=[128, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 150, 151, 152, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 185, 186, 188, 189, 190, 191], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(195, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 150, 151, 152, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172, 174, 175, 176, 178, 179, 180, 183, 185, 186, 188, 189, 190, 191], NumPruned=13056]
42840 parameters will be pruned
-------------

2023-05-31 17:14:14.152 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.5.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=22]
[ <DEP: prune_batchnorm => prune_conv on model.5.conv (Conv2d(6, 13, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=66]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.6.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12], NumPruned=6336]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 141, 144])>, Index=[128, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[128, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140], NumPruned=2816]
9240 parameters will be pruned
-------------

2023-05-31 17:14:14.153 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.6.conv (Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=918]
[ <DEP: prune_conv => prune_batchnorm on model.6.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63], NumPruned=29376]
30396 parameters will be pruned
-------------

2023-05-31 17:14:14.154 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.6.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.6.conv (Conv2d(2, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=180]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.7.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 2, 3, 4, 5, 6, 7, 8, 9, 12], NumPruned=5760]
5960 parameters will be pruned
-------------

2023-05-31 17:14:14.155 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.7.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=1377]
[ <DEP: prune_conv => prune_batchnorm on model.7.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 51, 53, 54, 55, 57, 60, 61, 62, 63], NumPruned=29376]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 128, 130, 133])>, Index=[64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 111, 113, 114, 115, 117, 118, 119, 121, 124, 125, 126, 127], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(133, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 111, 113, 114, 115, 117, 118, 119, 121, 124, 125, 126, 127], NumPruned=13056]
43911 parameters will be pruned
-------------

2023-05-31 17:14:14.155 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.7.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=20]
[ <DEP: prune_batchnorm => prune_conv on model.7.conv (Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=270]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.8.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 7, 9, 11, 12], NumPruned=5760]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 77, 79, 82])>, Index=[64, 65, 66, 67, 69, 70, 71, 73, 75, 76], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(82, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[64, 65, 66, 67, 69, 70, 71, 73, 75, 76], NumPruned=2560]
8610 parameters will be pruned
-------------

2023-05-31 17:14:14.156 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.8.conv (Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=1377]
[ <DEP: prune_conv => prune_batchnorm on model.8.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 4, 6, 7, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61], NumPruned=29376]
30855 parameters will be pruned
-------------

2023-05-31 17:14:14.157 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.8.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=22]
[ <DEP: prune_batchnorm => prune_conv on model.8.conv (Conv2d(3, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=297]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => prune_related_conv on model.9.conv (Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12], NumPruned=6336]
6655 parameters will be pruned
-------------

2023-05-31 17:14:14.158 | INFO     | __main__:layer_pruning:73 - 
-------------
[ <DEP: prune_conv => prune_conv on model.9.conv (Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=918]
[ <DEP: prune_conv => prune_batchnorm on model.9.bn (BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=102]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 64, 67, 69, 72])>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(72, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[1, 3, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63], NumPruned=13056]
14076 parameters will be pruned
-------------

2023-05-31 17:14:14.158 | INFO     | __main__:layer_pruning:79 - 
-------------
[ <DEP: prune_batchnorm => prune_batchnorm on model.9.bn (BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=22]
[ <DEP: prune_batchnorm => prune_conv on model.9.conv (Conv2d(2, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=198]
[ <DEP: prune_batchnorm => _prune_elementwise_op on _ElementWiseOp()>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=0]
[ <DEP: _prune_elementwise_op => _prune_concat on _ConcatOp([0, 13, 16, 18, 21])>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=0]
[ <DEP: _prune_concat => prune_related_conv on model.11.conv (Conv2d(21, 256, kernel_size=(1, 1), stride=(1, 1), bias=False))>, Index=[0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 12], NumPruned=2816]
3036 parameters will be pruned
-------------

2023-05-31 17:14:14.160 | INFO     | __main__:layer_pruning:84 -   Params: 37196556 => 36839172

2023-05-31 17:14:14.285 | INFO     | __main__:layer_pruning:95 - 剪枝完成

